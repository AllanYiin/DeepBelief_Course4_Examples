{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自編碼器Auto-Encoder  (cntk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###測試於cntk 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "首先引用所有需要的包，其中pickle是用來讀取或是儲存二進位檔(我已經事先將Minist數據處理成二進位檔)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import codecs\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "import cntk as C\n",
    "from cntk.ops import *\n",
    "from cntk.layers import *\n",
    "from cntk.losses import *\n",
    "from cntk.metrics import *\n",
    "from cntk.debugging import *\n",
    "from cntk.logging import *\n",
    "from cntk.learners import *\n",
    "from cntk.train import *\n",
    "from cntk.device import *\n",
    "\n",
    "# 是否使用GPU\n",
    "is_gpu = True\n",
    "if is_gpu:\n",
    "    try_set_default_device(gpu(0))\n",
    "else:\n",
    "    try_set_default_device(cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.__version__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "將mnist數據進行轉換，請注意，在cntk需要將output轉為onehot(利用np.eye函數)。對於feature除以255，是為了將像素值控制在0~1之間，這樣收斂比較快"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(60000, 784)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "train_data=None\n",
    "test_data=None\n",
    "\n",
    "with open('../Data/mnist_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "with open('../Data/mnist_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "    \n",
    "def parse_mnist(data):\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    for row in data:\n",
    "        labels.append(np.eye(10)[row[-1]].astype(np.float32))\n",
    "        features.append(row[:-1].astype(np.float32)/255.0)#正規化\n",
    "    return np.asarray(features),np.asarray(labels)\n",
    "\n",
    "features,labels=parse_mnist(train_data)\n",
    "print(features[:3])\n",
    "\n",
    "idxs=np.arange(0,train_data.shape[0])\n",
    "random.shuffle(idxs)\n",
    "idx=0\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 784)\n",
      "(3, 10)\n"
     ]
    }
   ],
   "source": [
    "def get_next_minibatch(minibatch_size):\n",
    "    global idxs,idx\n",
    "    x_features=[]\n",
    "    y_labels=[]\n",
    "    while len(x_features)<minibatch_size:\n",
    "        x_features.append(features[idxs[idx]])\n",
    "        y_labels.append(labels[idxs[idx]])\n",
    "        idx+=1\n",
    "        if idx>=len(idxs):\n",
    "            idx=0\n",
    "            random.shuffle(idxs)\n",
    "    return np.asarray(x_features).astype(np.float32),np.asarray(y_labels).astype(np.float32)\n",
    "\n",
    "features_x,labels_y=get_next_minibatch(3)\n",
    "print(features_x.shape)\n",
    "print(labels_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSPgQSPgQ6F87rjU5dRj2oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21b6aa7d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=Image.fromarray(np.reshape(features[0,:]*255,(28,28)).astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n",
    "\n",
    "print(labels[0,:])\n",
    "print(np.argmax(labels[0,:]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "以下我設計了三種autoencoder結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder(x):#基本型\n",
    "    x=Dense(784,activation=C.relu)(x)\n",
    "    x=Dense(512,activation=C.relu)(x)\n",
    "    x=Dense(256,activation=C.relu)(x)\n",
    "    x=Dense(128,activation=C.relu)(x)\n",
    "    x=Dense(64,activation=C.relu)(x)\n",
    "    x=Dense(32,activation=None)(x)\n",
    "    x=Dense(64,activation=C.relu)(x)\n",
    "    x=Dense(128,activation=C.relu)(x)\n",
    "    x=Dense(256,activation=C.relu)(x)\n",
    "    x=Dense(512,activation=C.relu)(x)\n",
    "    x=Dense(784,activation=C.relu)(x)\n",
    "    x=clip(x,0,1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder1(x):#加入批次正規化\n",
    "    x=Dense(784,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(512,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(256,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(64,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(32,activation=None)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(64,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(256,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(512,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(784,activation=C.relu)(x)\n",
    "    x=clip(x,0,1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder2(x):#加入dropout\n",
    "    x=Dense(784,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(512,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(256,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dropout(0.2)(x)\n",
    "    x=Dense(128,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(64,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(32,activation=None)(x)\n",
    "    x=Dense(64,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(256,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(512,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(784,activation=C.relu)(x)\n",
    "    x=clip(x,0,1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_var=C.input_variable(784, dtype=np.float32, name='input_var')\n",
    "\n",
    "z=autoencoder1(input_var)\n",
    "\n",
    "loss=reduce_mean(squared_error(z,input_var))\n",
    "errs=sqrt(reduce_sum(squared_error(z,input_var)/reduce_sum(input_var)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "progress_printer = ProgressPrinter(freq=200, tag='Training', num_epochs=300)\n",
    "\n",
    "learning_rate=0.001\n",
    "minibatch_size=64\n",
    "num_epochs=3\n",
    "learner = adam(z.parameters, lr=learning_rate_schedule([learning_rate], UnitType.sample, 300),\n",
    "               momentum=momentum_as_time_constant_schedule([minibatch_size / -math.log(0.95)], epoch_size=300),\n",
    "               l1_regularization_weight=0.0001, l2_regularization_weight=5e-3)\n",
    "\n",
    "trainer = Trainer(z, (loss, errs), learner, progress_printer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate per 1 samples: 0.001\n",
      " Minibatch[   1- 200]: loss = 55.706929 * 12800, metric = 71.14% * 12800;\n",
      " Minibatch[ 201- 400]: loss = 29.376050 * 12800, metric = 52.89% * 12800;\n",
      " Minibatch[ 401- 600]: loss = 25.328633 * 12800, metric = 48.72% * 12800;\n"
     ]
    }
   ],
   "source": [
    "for epoch_count in range(num_epochs):\n",
    "    mbs = 0\n",
    "    while mbs < len(features)/minibatch_size:\n",
    "        raw_features,raw_labels=get_next_minibatch(minibatch_size)\n",
    "        trainer.train_minibatch({input_var: raw_features})\n",
    "        if mbs%5==0:\n",
    "            z.save('Models/autoencoder_cntk.onnx', format=C.ModelFormat.ONNX)\n",
    "        mbs+=1\n",
    "    trainer.summarize_training_progress()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "問題\n",
    "(1)為何最中間層的活化函數為None(還有哪些選擇呢?)\n",
    "(2)最後一層的活化函數你覺得relu,sigmoid,leaky relu哪效果比較好呢?\n",
    "(3)三種自編碼器哪一種效果比較好(有沒有和預期不同的地方)\n",
    "(4)如果數值正規化方式改為減127.5除以127.5，請問模型結構該如何調整呢?\n",
    "(5)如果是你 ，還可以如何修改網路結構讓效果更好呢?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下來我們比對一下輸入與輸出的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results=z(raw_features)#產生預測結果\n",
    "#實際值\n",
    "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
    "print(actual.shape)\n",
    "print(pred.shape)\n",
    "img=Image.fromarray(np.concatenate([actual,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去噪自編碼器 Denoise AutoEncoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "所謂的去噪自編碼器，輸入值是添加了噪音的數據，但是輸出卻希望他能還原回原來乾淨的數據，這個做法等於是強迫模型自己找出噪音與真實數據間的差異進而分離純化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Images/denoise.jpg\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "所以唯一需要修正之處在於產生添加噪音的輸入值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_next_noise_minibatch(minibatch_size):\n",
    "    global idxs,idx\n",
    "    x_features=[]\n",
    "    x_noise=[]\n",
    "    while len(x_features)<minibatch_size:\n",
    "        x_features.append(features[idxs[idx]])\n",
    "        x_noise.append(features[idxs[idx]]+np.random.standard_normal(784)*0.005)\n",
    "        idx+=1\n",
    "        if idx>=len(idxs):\n",
    "            idx=0\n",
    "            random.shuffle(idxs)\n",
    "    return np.asarray(x_features).astype(np.float32),np.asarray(x_noise).astype(np.float32)\n",
    "\n",
    "features_x,noise_x=get_next_noise_minibatch(3)\n",
    "actual=np.reshape(features_x[0,:]*255,(28,28)).astype(np.uint8)\n",
    "noise=np.reshape(noise_x[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,noise],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "雖然輸入含噪音數據，但是損失函數則需要比對乾淨的原始值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_var=C.input_variable(784, dtype=np.float32, name='input_var')\n",
    "noise_var=C.input_variable(784, dtype=np.float32, name='input_var')\n",
    "\n",
    "z_denoise=autoencoder1(noise_var)\n",
    "\n",
    "loss=reduce_sum(squared_error(z_denoise,input_var))\n",
    "errs=sqrt(reduce_sum(squared_error(z_denoise,input_var)/reduce_sum(input_var)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learner = adam(z_denoise.parameters, lr=learning_rate_schedule([learning_rate], UnitType.sample, 300),\n",
    "               momentum=momentum_as_time_constant_schedule([minibatch_size / -math.log(0.95)], epoch_size=300),\n",
    "               l1_regularization_weight=0.0001, l2_regularization_weight=5e-3)\n",
    "\n",
    "trainer = Trainer(z_denoise, (loss, errs), learner, progress_printer)\n",
    "\n",
    "for epoch_count in range(num_epochs):\n",
    "    mbs = 0\n",
    "    while mbs < len(features)/minibatch_size:\n",
    "        raw_features,raw_noise=get_next_noise_minibatch(minibatch_size)\n",
    "        trainer.train_minibatch({input_var: raw_features,noise_var:raw_noise})\n",
    "        if mbs%5==0:\n",
    "            z_denoise.save('Models/denoise_autoencoder_cntk.onnx', format=C.ModelFormat.ONNX)\n",
    "        mbs+=1\n",
    "    trainer.summarize_training_progress()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "比對原始數據、添加噪音數據以及最後模型生成值，可以看到神經網路學會了如何區分噪音與信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_features,raw_noise=get_next_noise_minibatch(minibatch_size)\n",
    "results=z_denoise(raw_noise)#產生預測結果\n",
    "#實際值\n",
    "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
    "noise=np.reshape(raw_noise[0,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,noise,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 變分自編碼器（VAE）"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "變分自編碼器雖然名字叫做自編碼器，但實際上與自編碼器沒有太多關係，相對的，他反而很常被拿來與GAN相提並論，它的目的都是透過一個隱向量的分布來去生成一群樣本。變分自編碼器不管原始樣本的分布是如何，他都強制轉換為一個常態分配的分布，也就是他的作用是用來進行強制分布變換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vae_encoder(x):\n",
    "    x=Dense(784,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(512,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(256,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(64,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def vae_decoder(x):\n",
    "    x=Dense(32,activation=None)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(64,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(128,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(256,activation=C.relu)(x)\n",
    "    x=BatchNormalization()(x)\n",
    "    x=Dense(512,activation=C.relu)(x)\n",
    " \n",
    " \n",
    "    return x\n",
    "\n",
    "latent_dim = 32 # 隱變量維度數\n",
    "\n",
    "h = vae_encoder(input_var)\n",
    "\n",
    "# 算p(Z|X)的均值和方差\n",
    "z_mean = Dense(32)(h)\n",
    "z_log_var = Dense(32)(h)\n",
    "\n",
    "\n",
    "#epsilon表示隨機成分\n",
    "epsilon =C.random.normal(shape=(latent_dim), mean=0.,scale=1)\n",
    "z=z_mean +exp(z_log_var/2)#* epsilon\n",
    "\n",
    "#如果不處理epsilon，則為AUTOENCODER\n",
    "#如果處理epsilon，則為生成模型\n",
    "\n",
    "\n",
    "#解碼層\n",
    "decoder_mean = Dense(784, activation=sigmoid)\n",
    "h_decoded = vae_decoder(z)\n",
    "z_vae= decoder_mean(h_decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xent_loss = 784*binary_cross_entropy(z_vae,input_var)#重構損失\n",
    "kl_loss = - 0.5 * reduce_sum(1 + z_log_var - square(z_mean) - exp(z_log_var), axis=-1)#KL散度\n",
    "vae_loss = reduce_mean(xent_loss + kl_loss)\n",
    "\n",
    "loss=vae_loss\n",
    "errs=sqrt(reduce_sum(squared_error(z_vae,input_var)/reduce_sum(input_var)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "progress_printer = ProgressPrinter(freq=200, tag='Training', num_epochs=300)\n",
    "\n",
    "learning_rate=0.0001\n",
    "minibatch_size=64\n",
    "num_epochs=5\n",
    "learner = adam(z_vae.parameters, lr=learning_rate_schedule([learning_rate], UnitType.sample, 300),\n",
    "               momentum=momentum_as_time_constant_schedule([minibatch_size / -math.log(0.95)], epoch_size=300),\n",
    "               l1_regularization_weight=0.0001, l2_regularization_weight=5e-3)\n",
    "\n",
    "trainer = Trainer(z_vae, (loss, errs), learner, progress_printer)\n",
    "for epoch_count in range(num_epochs):\n",
    "    mbs = 0\n",
    "    while mbs < len(features)/minibatch_size:\n",
    "        raw_features,raw_labels=get_next_minibatch(minibatch_size)\n",
    "        trainer.train_minibatch({input_var: raw_features})\n",
    "        if mbs%5==0:\n",
    "            z_vae.save('Models/vae_cntk.model')\n",
    "        mbs+=1\n",
    "    trainer.summarize_training_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_features,raw_labels=get_next_minibatch(minibatch_size)\n",
    "results=z_vae(raw_features)#產生預測結果\n",
    "#實際值\n",
    "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
