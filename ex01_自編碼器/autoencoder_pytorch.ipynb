{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自編碼器Auto-Encoder  (pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###測試於pytorch 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "首先引用所有需要的包，其中pickle是用來讀取或是儲存二進位檔(我已經事先將Minist數據處理成二進位檔)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import codecs\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "將mnist數據進行轉換，請注意，在pytorch不需要將output轉為onehot，而且需要將他轉型為int64，以配合生成LongTensor。對於feature除以255，是為了將像素值控制在0~1之間，這樣收斂比較快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "train_data=None\n",
    "test_data=None\n",
    "\n",
    "with open('../Data/mnist_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    print(len(train_data))\n",
    "with open('../Data/mnist_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "    print(len(test_data))\n",
    "    \n",
    "def parse_mnist(data):\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    for row in data:\n",
    "        labels.append(row[-1].astype(np.int64))\n",
    "        features.append(row[:-1].astype(np.float32)/255.0)\n",
    "    return np.asarray(features),np.asarray(labels)\n",
    "\n",
    "features,labels=parse_mnist(train_data)\n",
    "print(features[:3])\n",
    "\n",
    "idxs=np.arange(0,train_data.shape[0])\n",
    "random.shuffle(idxs)\n",
    "idx=0\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 784)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "def get_next_minibatch(minibatch_size):\n",
    "    global idxs,idx\n",
    "    x_features=[]\n",
    "    y_labels=[]\n",
    "    while len(x_features)<minibatch_size:\n",
    "        x_features.append(features[idxs[idx]])\n",
    "        y_labels.append(labels[idxs[idx]])\n",
    "        idx+=1\n",
    "        if idx>=len(idxs):\n",
    "            idx=0\n",
    "            random.shuffle(idxs)\n",
    "    return np.asarray(x_features).astype(np.float32),np.asarray(y_labels).astype(np.float32)\n",
    "\n",
    "features_x,labels_y=get_next_minibatch(3)\n",
    "print(features_x.shape)\n",
    "print(labels_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABqVJREFUeJzt3TtI1n0fx/HneoqGOypxKQgibDAqwqWCCCJCIqjBahGa\niqaEJpe2BiPoMEQNTkFLNHZYarDDEAjSYRHaC7eyg50wr3tz6vmKXF6P5uf1Gv3Q/f8P95vf8Otv\njWaz+R8gy38X+wWA/z/hQyDhQyDhQyDhQyDhQyDhQ6CV7X5Ao9HwFwVgkTSbzcaffu7Eh0DCh0DC\nh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DC\nh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0DCh0ArF/sFaK8V\nK1aU+7p169r6/IGBgXL/559/yr27u7vcz549W+5Xrlwp9/7+/nL/8eNHuV+6dKncL1y4UO6LxYkP\ngYQPgYQPgYQPgYQPgYQPgYQPgdzjt9mmTZvKfdWqVeW+d+/ect+3b1+5d3R0lPvx48fLfbG9e/eu\n3K9fv17ufX195f7ly5dyf/PmTbk/e/as3JcqJz4EEj4EEj4EEj4EEj4EEj4EEj4EajSbzfY+oNFo\n7wMWWU9PT7mPjIyUe7u/h1/qZmZmyv3UqVPl/vXr15aePzExUe4fP34s97dv37b0/HZrNpuNP/3c\niQ+BhA+BhA+BhA+BhA+BhA+BhA+B3OO3qLOzs9xHR0fLvaurayFfZ8HN9f6Tk5PlfuDAgXL/9etX\nuaf/PYdWuccHZgkfAgkfAgkfAgkfAgkfAgkfAvm9+i368OFDuQ8ODpb7kSNHyv3Vq1flPtfvlZ/L\n69evy723t7fcp6amyn379u3lfu7cuXKnPZz4EEj4EEj4EEj4EEj4EEj4EEj4EMj3+Its7dq15T7X\nv98+PDxc7qdPny73kydPlvudO3fKnaXN9/jALOFDIOFDIOFDIOFDIOFDIOFDIN/jL7LPnz+39Oc/\nffrU0p8/c+ZMud+9e7fc5/r37VmanPgQSPgQSPgQSPgQSPgQSPgQSPgQyPf4f7nVq1eX+4MHD8p9\n//795X748OFyf/z4cbmzuHyPD8wSPgQSPgQSPgQSPgQSPgQSPgRyj7/MbdmypdxfvnxZ7pOTk+X+\n5MmTch8bGyv3mzdvlnu7//9c7tzjA7OED4GED4GED4GED4GED4GED4Hc44fr6+sr91u3bpX7mjVr\nWnr++fPny/327dvlPjEx0dLzlzv3+MAs4UMg4UMg4UMg4UMg4UMg4UMg9/iUduzYUe7Xrl0r94MH\nD7b0/OHh4XIfGhoq9/fv37f0/L+de3xglvAhkPAhkPAhkPAhkPAhkPAhkHt8WtLR0VHuR48eLfe5\nvvdvNP54DT1rZGSk3Ht7e8t9uXOPD8wSPgQSPgQSPgQSPgQSPgQSPgRyj8+i+vnzZ7mvXLmy3Ken\np8v90KFD5f706dNy/9u5xwdmCR8CCR8CCR8CCR8CCR8CCR8C1ZekxNu5c2e5nzhxotx37dpV7nPd\n089lfHy83J8/f97Sf3+5cuJDIOFDIOFDIOFDIOFDIOFDIOFDIPf4y1x3d3e5DwwMlPuxY8fKfcOG\nDfN+p/n4/ft3uU9MTJT7zMzMQr7OsuHEh0DCh0DCh0DCh0DCh0DCh0DCh0Du8Ze4ue7J+/v7y32u\ne/rNmzfP95UW1NjYWLkPDQ2V+/379xfydWI48SGQ8CGQ8CGQ8CGQ8CGQ8CGQ8CGQe/w2W79+fblv\n27at3G/cuFHuW7dunfc7LaTR0dFyv3z5crnfu3ev3H1P3x5OfAgkfAgkfAgkfAgkfAgkfAgkfAjk\nHn8OnZ2d5T48PFzuPT095d7V1TXvd1pIL168KPerV6+W+6NHj8r9+/fv834n2s+JD4GED4GED4GE\nD4GED4GED4GED4GW/T3+nj17yn1wcLDcd+/eXe4bN26c9zstpG/fvpX79evXy/3ixYvlPjU1Ne93\nYulz4kMg4UMg4UMg4UMg4UMg4UMg4UOgZX+P39fX19LeqvHx8XJ/+PBhuU9PT5f7XN/LT05OljuZ\nnPgQSPgQSPgQSPgQSPgQSPgQSPgQqNFsNtv7gEajvQ8A/qdms9n408+d+BBI+BBI+BBI+BBI+BBI\n+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BBI+BCo7b9X\nH1h6nPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQSPgQ\nSPgQSPgQ6F87rjU5dRj2oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce3e1dd940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=Image.fromarray(np.reshape(features[0,:]*255,(28,28)).astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n",
    "\n",
    "print(labels[0])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "以下我設計了三種autoencoder結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.d1 = nn.Linear(784, 512)\n",
    "        self.d2 = nn.Linear(512, 256)\n",
    "        self.d3 = nn.Linear(256, 128)\n",
    "        self.d4 = nn.Linear(128, 64)\n",
    "        self.d5 = nn.Linear(64, 32)\n",
    "        self.d6 = nn.Linear(32, 64)\n",
    "        self.d7 = nn.Linear(64, 128)\n",
    "        self.d8 = nn.Linear(128, 256)\n",
    "        self.d9 = nn.Linear(256, 512)\n",
    "        self.d10 = nn.Linear(512, 784)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = F.relu(self.d2(x))\n",
    "        x = F.relu(self.d3(x))\n",
    "        x = F.relu(self.d4(x))\n",
    "        x = self.d5(x)\n",
    "        x = F.relu(self.d6(x))\n",
    "        x = F.relu(self.d7(x))\n",
    "        x = F.relu(self.d8(x))\n",
    "        x = F.relu(self.d9(x))\n",
    "        x = F.relu(self.d10(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder1, self).__init__()\n",
    "        self.d1 = nn.Linear(784, 512)\n",
    "        self.d2 = nn.Linear(512, 256)\n",
    "        self.d3 = nn.Linear(256, 128)\n",
    "        self.d4 = nn.Linear(128, 64)\n",
    "        self.d5 = nn.Linear(64, 32)\n",
    "        self.d6 = nn.Linear(32, 64)\n",
    "        self.d7 = nn.Linear(64, 128)\n",
    "        self.d8 = nn.Linear(128, 256)\n",
    "        self.d9 = nn.Linear(256, 512)\n",
    "        self.d10 = nn.Linear(512, 784)\n",
    "        self.b1=nn.BatchNorm1d(num_features=512)\n",
    "        self.b2=nn.BatchNorm1d(num_features=256)\n",
    "        self.b3=nn.BatchNorm1d(num_features=128)\n",
    "        self.b4=nn.BatchNorm1d(num_features=64)\n",
    "        self.b5=nn.BatchNorm1d(num_features=32)\n",
    "        self.b6=nn.BatchNorm1d(num_features=64)\n",
    "        self.b7=nn.BatchNorm1d(num_features=128)\n",
    "        self.b8=nn.BatchNorm1d(num_features=256)\n",
    "        self.b9=nn.BatchNorm1d(num_features=512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x =self.b1(x)\n",
    "        x = F.relu(self.d2(x))\n",
    "        x =self.b2(x)\n",
    "        x = F.relu(self.d3(x))\n",
    "        x =self.b3(x)\n",
    "        x = F.relu(self.d4(x))\n",
    "        x =self.b4(x)\n",
    "        x = self.d5(x)\n",
    "        x =self.b5(x)\n",
    "        x = F.relu(self.d6(x))\n",
    "        x =self.b6(x)\n",
    "        x = F.relu(self.d7(x))\n",
    "        x =self.b7(x)\n",
    "        x = F.relu(self.d8(x))\n",
    "        x =self.b8(x)\n",
    "        x = F.relu(self.d9(x))\n",
    "        x =self.b9(x)\n",
    "        x = F.relu(self.d10(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder2, self).__init__()\n",
    "        self.d1 = nn.Linear(784, 512)\n",
    "        self.d2 = nn.Linear(512, 256)\n",
    "        self.d3 = nn.Linear(256, 128)\n",
    "        self.d4 = nn.Linear(128, 64)\n",
    "        self.d5 = nn.Linear(64, 32)\n",
    "        self.d6 = nn.Linear(32, 64)\n",
    "        self.d7 = nn.Linear(64, 128)\n",
    "        self.d8 = nn.Linear(128, 256)\n",
    "        self.d9 = nn.Linear(256, 512)\n",
    "        self.d10 = nn.Linear(512, 784)\n",
    "        self.b1=nn.BatchNorm1d(num_features=512)\n",
    "        self.b2=nn.BatchNorm1d(num_features=256)\n",
    "        self.b3=nn.BatchNorm1d(num_features=128)\n",
    "        self.b4=nn.BatchNorm1d(num_features=64)\n",
    "        self.b5=nn.BatchNorm1d(num_features=32)\n",
    "        self.b6=nn.BatchNorm1d(num_features=64)\n",
    "        self.b7=nn.BatchNorm1d(num_features=128)\n",
    "        self.b8=nn.BatchNorm1d(num_features=256)\n",
    "        self.b9=nn.BatchNorm1d(num_features=512)\n",
    "        self.drop1=nn.Dropout1d(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x =self.b1(x)\n",
    "        x = F.relu(self.d2(x))\n",
    "        x =self.b2(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.d3(x))\n",
    "        x =self.b3(x)\n",
    "        x = F.relu(self.d4(x))\n",
    "        x =self.b4(x)\n",
    "        x = self.d5(x)\n",
    "        x =self.b5(x)\n",
    "        x = F.relu(self.d6(x))\n",
    "        x =self.b6(x)\n",
    "        x = F.relu(self.d7(x))\n",
    "        x =self.b7(x)\n",
    "        x = F.relu(self.d8(x))\n",
    "        x =self.b8(x)\n",
    "        x = F.relu(self.d9(x))\n",
    "        x =self.b9(x)\n",
    "        x = F.relu(self.d10(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type autoencoder1. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 100... Loss: 0.0464...\n",
      "Epoch: 1/2... Step: 200... Loss: 0.0404...\n",
      "Epoch: 1/2... Step: 300... Loss: 0.0435...\n",
      "Epoch: 1/2... Step: 400... Loss: 0.0511...\n",
      "Epoch: 1/2... Step: 500... Loss: 0.0461...\n",
      "Epoch: 1/2... Step: 600... Loss: 0.0368...\n",
      "Epoch: 1/2... Step: 700... Loss: 0.0441...\n",
      "Epoch: 1/2... Step: 800... Loss: 0.0371...\n",
      "Epoch: 1/2... Step: 900... Loss: 0.0363...\n",
      "Epoch: 1/2... Step: 1000... Loss: 0.0352...\n",
      "Epoch: 1/2... Step: 1100... Loss: 0.0333...\n",
      "Epoch: 1/2... Step: 1200... Loss: 0.0361...\n",
      "Epoch: 1/2... Step: 1300... Loss: 0.0400...\n",
      "Epoch: 1/2... Step: 1400... Loss: 0.0382...\n",
      "Epoch: 1/2... Step: 1500... Loss: 0.0307...\n",
      "Epoch: 1/2... Step: 1600... Loss: 0.0344...\n",
      "Epoch: 1/2... Step: 1700... Loss: 0.0310...\n",
      "Epoch: 1/2... Step: 1800... Loss: 0.0331...\n",
      "Epoch: 2/2... Step: 100... Loss: 0.0353...\n",
      "Epoch: 2/2... Step: 200... Loss: 0.0265...\n",
      "Epoch: 2/2... Step: 300... Loss: 0.0369...\n",
      "Epoch: 2/2... Step: 400... Loss: 0.0348...\n",
      "Epoch: 2/2... Step: 500... Loss: 0.0332...\n",
      "Epoch: 2/2... Step: 600... Loss: 0.0346...\n",
      "Epoch: 2/2... Step: 700... Loss: 0.0315...\n",
      "Epoch: 2/2... Step: 800... Loss: 0.0351...\n",
      "Epoch: 2/2... Step: 900... Loss: 0.0314...\n",
      "Epoch: 2/2... Step: 1000... Loss: 0.0313...\n",
      "Epoch: 2/2... Step: 1100... Loss: 0.0356...\n",
      "Epoch: 2/2... Step: 1200... Loss: 0.0326...\n",
      "Epoch: 2/2... Step: 1300... Loss: 0.0383...\n",
      "Epoch: 2/2... Step: 1400... Loss: 0.0348...\n",
      "Epoch: 2/2... Step: 1500... Loss: 0.0287...\n",
      "Epoch: 2/2... Step: 1600... Loss: 0.0299...\n",
      "Epoch: 2/2... Step: 1700... Loss: 0.0310...\n",
      "Epoch: 2/2... Step: 1800... Loss: 0.0289...\n"
     ]
    }
   ],
   "source": [
    "model = autoencoder1()\n",
    "if use_cuda:\n",
    "    model= model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "ceriation = nn.MSELoss()\n",
    "num_epochs=2\n",
    "minibatch_size=32\n",
    "for epoch in range(num_epochs):\n",
    "    mbs=0\n",
    "    rows=0\n",
    "    ave_loss = 0\n",
    "    while rows < train_data.shape[0]:\n",
    "        optimizer.zero_grad()\n",
    "        features_x,label_y=get_next_minibatch(minibatch_size)\n",
    "        x, target = torch.from_numpy(features_x), torch.from_numpy(features_x)\n",
    "        if use_cuda:\n",
    "            x, target = x.cuda(), target.cuda()\n",
    "        x, target = Variable(x), Variable(target)\n",
    "        out = model(x)\n",
    "        loss = ceriation(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if mbs%100==0 and mbs>0:\n",
    "            print(\"Epoch: {}/{}...\".format(epoch+1, num_epochs),\n",
    "                          \"Step: {}...\".format(mbs),\n",
    "                          \"Loss: {:.4f}...\".format(loss.data.item()))\n",
    "        mbs+=1\n",
    "        rows+=minibatch_size\n",
    "        torch.save(model, 'Models/autoencoder_pytorch.cnn'.format(epoch))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "問題\n",
    "(1)為何最中間層的活化函數為None(還有哪些選擇呢?)\n",
    "(2)最後一層的活化函數你覺得relu,sigmoid,leaky relu哪效果比較好呢?\n",
    "(3)三種自編碼器哪一種效果比較好(有沒有和預期不同的地方)\n",
    "(4)如果數值正規化方式改為減127.5除以127.5，請問模型結構該如何調整呢?\n",
    "(5)如果是你 ，還可以如何修改網路結構讓效果更好呢?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下來我們比對一下輸入與輸出的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784)\n",
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce05492828>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADFCAYAAACfOaMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNkAhRhugEKMNUIjRBijEaAMU8i/yDoIGl0shNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce05492860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "x,y=get_next_minibatch(minibatch_size)\n",
    "input=torch.from_numpy(x)\n",
    "input=Variable(input)\n",
    "input=input.cuda()\n",
    "output = model(input)\n",
    "pred=output.cpu().detach().numpy()\n",
    "print(pred.shape)\n",
    "#實際值\n",
    "actual=np.reshape(x[1,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(pred[1,:]*255,(28,28)).astype(np.uint8)\n",
    "print(actual.shape)\n",
    "print(pred.shape)\n",
    "img=Image.fromarray(np.concatenate([actual,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去噪自編碼器 Denoise AutoEncoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "所謂的去噪自編碼器，輸入值是添加了噪音的數據，但是輸出卻希望他能還原回原來乾淨的數據，這個做法等於是強迫模型自己找出噪音與真實數據間的差異進而分離純化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Images/denoise.jpg\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "所以唯一需要修正之處在於產生添加噪音的輸入值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce3e7d0ba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADFCAYAAACfOaMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce3e498630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_next_noise_minibatch(minibatch_size):\n",
    "    global idxs,idx\n",
    "    x_features=[]\n",
    "    x_noise=[]\n",
    "    while len(x_features)<minibatch_size:\n",
    "        x_features.append(features[idxs[idx]])\n",
    "        x_noise.append(features[idxs[idx]]+np.random.standard_normal(784)*0.005)\n",
    "        idx+=1\n",
    "        if idx>=len(idxs):\n",
    "            idx=0\n",
    "            random.shuffle(idxs)\n",
    "    return np.asarray(x_features).astype(np.float32),np.asarray(x_noise).astype(np.float32)\n",
    "\n",
    "features_x,noise_x=get_next_noise_minibatch(3)\n",
    "actual=np.reshape(features_x[0,:]*255,(28,28)).astype(np.uint8)\n",
    "noise=np.reshape(noise_x[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,noise],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "雖然輸入含噪音數據，但是損失函數則需要比對乾淨的原始值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type autoencoder1. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 100... Loss: 0.0482...\n",
      "Epoch: 1/2... Step: 200... Loss: 0.0473...\n",
      "Epoch: 1/2... Step: 300... Loss: 0.0493...\n",
      "Epoch: 1/2... Step: 400... Loss: 0.0517...\n",
      "Epoch: 1/2... Step: 500... Loss: 0.0440...\n",
      "Epoch: 1/2... Step: 600... Loss: 0.0427...\n",
      "Epoch: 1/2... Step: 700... Loss: 0.0382...\n",
      "Epoch: 1/2... Step: 800... Loss: 0.0410...\n",
      "Epoch: 1/2... Step: 900... Loss: 0.0397...\n",
      "Epoch: 1/2... Step: 1000... Loss: 0.0301...\n",
      "Epoch: 1/2... Step: 1100... Loss: 0.0373...\n",
      "Epoch: 1/2... Step: 1200... Loss: 0.0357...\n",
      "Epoch: 1/2... Step: 1300... Loss: 0.0365...\n",
      "Epoch: 1/2... Step: 1400... Loss: 0.0322...\n",
      "Epoch: 1/2... Step: 1500... Loss: 0.0352...\n",
      "Epoch: 1/2... Step: 1600... Loss: 0.0415...\n",
      "Epoch: 1/2... Step: 1700... Loss: 0.0300...\n",
      "Epoch: 1/2... Step: 1800... Loss: 0.0354...\n",
      "Epoch: 2/2... Step: 100... Loss: 0.0329...\n",
      "Epoch: 2/2... Step: 200... Loss: 0.0328...\n",
      "Epoch: 2/2... Step: 300... Loss: 0.0278...\n",
      "Epoch: 2/2... Step: 400... Loss: 0.0369...\n",
      "Epoch: 2/2... Step: 500... Loss: 0.0320...\n",
      "Epoch: 2/2... Step: 600... Loss: 0.0369...\n",
      "Epoch: 2/2... Step: 700... Loss: 0.0300...\n",
      "Epoch: 2/2... Step: 800... Loss: 0.0336...\n",
      "Epoch: 2/2... Step: 900... Loss: 0.0304...\n",
      "Epoch: 2/2... Step: 1000... Loss: 0.0275...\n",
      "Epoch: 2/2... Step: 1100... Loss: 0.0275...\n",
      "Epoch: 2/2... Step: 1200... Loss: 0.0283...\n",
      "Epoch: 2/2... Step: 1300... Loss: 0.0301...\n",
      "Epoch: 2/2... Step: 1400... Loss: 0.0300...\n",
      "Epoch: 2/2... Step: 1500... Loss: 0.0285...\n",
      "Epoch: 2/2... Step: 1600... Loss: 0.0319...\n",
      "Epoch: 2/2... Step: 1700... Loss: 0.0386...\n",
      "Epoch: 2/2... Step: 1800... Loss: 0.0288...\n"
     ]
    }
   ],
   "source": [
    "model1 = autoencoder1()\n",
    "if use_cuda:\n",
    "    model1 = model1.cuda()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.01)\n",
    "ceriation = nn.MSELoss()\n",
    "num_epochs=2\n",
    "minibatch_size=32\n",
    "for epoch in range(num_epochs):\n",
    "    mbs=0\n",
    "    rows=0\n",
    "    ave_loss = 0\n",
    "    while rows < train_data.shape[0]:\n",
    "        optimizer.zero_grad()\n",
    "        features_x,noise_x=get_next_noise_minibatch(minibatch_size)\n",
    "        noise, target = torch.from_numpy(noise_x), torch.from_numpy(features_x)\n",
    "        if use_cuda:\n",
    "            noise, target = noise.cuda(), target.cuda()\n",
    "        noise, target = Variable(noise), Variable(target)\n",
    "        out = model1(noise)\n",
    "        loss = ceriation(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if mbs%100==0 and mbs>0:\n",
    "            print(\"Epoch: {}/{}...\".format(epoch+1, num_epochs),\n",
    "                          \"Step: {}...\".format(mbs),\n",
    "                          \"Loss: {:.4f}...\".format(loss.data.item()))\n",
    "        mbs+=1\n",
    "        rows+=minibatch_size\n",
    "        torch.save(model1, 'Models/denoise_autoencoder_pytorch.cnn'.format(epoch))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "比對原始數據、添加噪音數據以及最後模型生成值，可以看到神經網路學會了如何區分噪音與信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce054849e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAACPCAYAAAAx+oofAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce05484da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_features,raw_noise=get_next_noise_minibatch(minibatch_size)\n",
    "input=torch.from_numpy(raw_noise)\n",
    "input=Variable(input)\n",
    "input=input.cuda()\n",
    "output = model1(input)\n",
    "results=output.cpu().detach().numpy()\n",
    "#實際值\n",
    "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
    "noise=np.reshape(raw_noise[0,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,noise,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 變分自編碼器（VAE）"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "變分自編碼器雖然名字叫做自編碼器，但實際上與自編碼器沒有太多關係，相對的，他反而很常被拿來與GAN相提並論，它的目的都是透過一個隱向量的分布來去生成一群樣本。變分自編碼器不管原始樣本的分布是如何，他都強制轉換為一個常態分配的分布，也就是他的作用是用來進行強制分布變換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class vae_encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vae_encoder, self).__init__()\n",
    "        self.d1 = nn.Linear(784, 512)\n",
    "        self.d2 = nn.Linear(512, 256)\n",
    "        self.d3 = nn.Linear(256, 128)\n",
    "        self.d4 = nn.Linear(128, 64)\n",
    "        self.d5 = nn.Linear(64, 32)\n",
    "        self.d6 = nn.Linear(64, 32)\n",
    "        self.b1=nn.BatchNorm1d(num_features=512)\n",
    "        self.b2=nn.BatchNorm1d(num_features=256)\n",
    "        self.b3=nn.BatchNorm1d(num_features=128)\n",
    "        self.b4=nn.BatchNorm1d(num_features=64)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x =self.b1(x)\n",
    "        x = F.relu(self.d2(x))\n",
    "        x =self.b2(x)\n",
    "        x = F.relu(self.d3(x))\n",
    "        x =self.b3(x)\n",
    "        x = F.relu(self.d4(x))\n",
    "        x =self.b4(x)\n",
    "        return self.d5(x),self.d6(x)\n",
    "    \n",
    "    \n",
    "class vae_decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vae_decoder, self).__init__()\n",
    "        self.d6 = nn.Linear(32, 64)\n",
    "        self.d7 = nn.Linear(64, 128)\n",
    "        self.d8 = nn.Linear(128, 256)\n",
    "        self.d9 = nn.Linear(256, 512)\n",
    "        self.d10 = nn.Linear(512, 784)\n",
    "        self.b6=nn.BatchNorm1d(num_features=64)\n",
    "        self.b7=nn.BatchNorm1d(num_features=128)\n",
    "        self.b8=nn.BatchNorm1d(num_features=256)\n",
    "        self.b9=nn.BatchNorm1d(num_features=512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32)\n",
    "        x = F.relu(self.d6(x))\n",
    "        x =self.b6(x)\n",
    "        x = F.relu(self.d7(x))\n",
    "        x =self.b7(x)\n",
    "        x = F.relu(self.d8(x))\n",
    "        x =self.b8(x)\n",
    "        x = F.relu(self.d9(x))\n",
    "        x =self.b9(x)\n",
    "        x = F.relu(self.d10(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class vae(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vae, self).__init__()\n",
    "        self.encoder= vae_encoder()\n",
    "        self.decoder = vae_decoder()\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x.view(-1, 784))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decoder(z),mu, logvar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "recon_loss = nn.MSELoss()\n",
    "recon_loss.size_average = False\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = recon_loss(recon_x, x.view(-1, 784))\n",
    "\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    return BCE+KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type vae. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type vae_encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type vae_decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 100... Loss: 0.1244...\n",
      "Epoch: 1/2... Step: 200... Loss: 0.0925...\n",
      "Epoch: 1/2... Step: 300... Loss: 0.0777...\n",
      "Epoch: 1/2... Step: 400... Loss: 0.0869...\n",
      "Epoch: 1/2... Step: 500... Loss: 0.0814...\n",
      "Epoch: 1/2... Step: 600... Loss: 0.0815...\n",
      "Epoch: 1/2... Step: 700... Loss: 0.0729...\n",
      "Epoch: 1/2... Step: 800... Loss: 0.0749...\n",
      "Epoch: 1/2... Step: 900... Loss: 0.0703...\n",
      "Epoch: 1/2... Step: 1000... Loss: 0.0718...\n",
      "Epoch: 1/2... Step: 1100... Loss: 0.0700...\n",
      "Epoch: 1/2... Step: 1200... Loss: 0.0723...\n",
      "Epoch: 1/2... Step: 1300... Loss: 0.0695...\n",
      "Epoch: 1/2... Step: 1400... Loss: 0.0703...\n",
      "Epoch: 1/2... Step: 1500... Loss: 0.0643...\n",
      "Epoch: 1/2... Step: 1600... Loss: 0.0744...\n",
      "Epoch: 1/2... Step: 1700... Loss: 0.0789...\n",
      "Epoch: 1/2... Step: 1800... Loss: 0.0691...\n",
      "Epoch: 2/2... Step: 100... Loss: 0.0703...\n",
      "Epoch: 2/2... Step: 200... Loss: 0.0736...\n",
      "Epoch: 2/2... Step: 300... Loss: 0.0696...\n",
      "Epoch: 2/2... Step: 400... Loss: 0.0729...\n",
      "Epoch: 2/2... Step: 500... Loss: 0.0686...\n",
      "Epoch: 2/2... Step: 600... Loss: 0.0718...\n",
      "Epoch: 2/2... Step: 700... Loss: 0.0715...\n",
      "Epoch: 2/2... Step: 800... Loss: 0.0693...\n",
      "Epoch: 2/2... Step: 900... Loss: 0.0700...\n",
      "Epoch: 2/2... Step: 1000... Loss: 0.0744...\n",
      "Epoch: 2/2... Step: 1100... Loss: 0.0695...\n",
      "Epoch: 2/2... Step: 1200... Loss: 0.0703...\n",
      "Epoch: 2/2... Step: 1300... Loss: 0.0741...\n",
      "Epoch: 2/2... Step: 1400... Loss: 0.0665...\n",
      "Epoch: 2/2... Step: 1500... Loss: 0.0713...\n",
      "Epoch: 2/2... Step: 1600... Loss: 0.0801...\n",
      "Epoch: 2/2... Step: 1700... Loss: 0.0698...\n",
      "Epoch: 2/2... Step: 1800... Loss: 0.0690...\n"
     ]
    }
   ],
   "source": [
    "model2 = vae()\n",
    "if use_cuda:\n",
    "    model2 = model2.cuda()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs=2\n",
    "minibatch_size=32\n",
    "for epoch in range(num_epochs):\n",
    "    mbs=0\n",
    "    rows=0\n",
    "    while rows < train_data.shape[0]:\n",
    "        optimizer.zero_grad()\n",
    "        x,y=get_next_minibatch(minibatch_size)\n",
    "        x = torch.from_numpy(x.astype(np.float32))\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        x= Variable(x)\n",
    "        z_vae, mu, logvar = model2(x)\n",
    "        loss = vae_loss(z_vae, x, mu, logvar)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if mbs%100==0 and mbs>0:\n",
    "            print(\"Epoch: {}/{}...\".format(epoch+1, num_epochs),\n",
    "                          \"Step: {}...\".format(mbs),\n",
    "                          \"Loss: {:.4f}...\".format(loss.data.item()))\n",
    "        mbs+=1\n",
    "        rows+=minibatch_size\n",
    "        torch.save(model2, 'Models/vae_pytorch.cnn'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ce096d9470>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADFCAYAAACfOaMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ce096d9198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_features,raw_labels=get_next_minibatch(minibatch_size)\n",
    "input=torch.from_numpy(raw_features)\n",
    "input=Variable(input)\n",
    "input=input.cuda()\n",
    "z_vae, mu, logvar = model2(input)\n",
    "results=z_vae.cpu().detach().numpy()\n",
    "#實際值\n",
    "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
