{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 賦值與基本運算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "前面介紹過了利用索引的概念來取值，接下來我們就可以很容易理解另一種向量的基礎操作「賦值」，也就是在指定範圍內修改向量內的值。最基礎的賦值就是用等號來給予值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "(4, 3)\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 1  1  1]\n",
      " [10 11 12]]\n",
      "[[ 1  2  3]\n",
      " [ 4  1  6]\n",
      " [ 7  1  9]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "x1=x.copy() #把向量複製一份，免得修改到原始結構\n",
    "x1[2]=1 #將第一個維度索引為2的全部修改為1\n",
    "print(x1)\n",
    "\n",
    "x2=x.copy() #把向量複製一份，免得修改到原始結構\n",
    "x2[1:3,1:2]=1\n",
    "print(x2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "前面提到的都是在於我們已經知道了他的固定位置，然後我們再來取值賦值。但若是我們是根據條件式來判定，若是符合條件式則賦值那要怎麼做呢?基本上只需要在中括號裡撰寫條件式即可，若有多個條件利用&(和)|(或)串接即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "(4, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 1]\n",
      " [1 1 1]]\n",
      "[[ 1  2  3]\n",
      " [ 4  5  1]\n",
      " [ 1  1  9]\n",
      " [10 11 12]]\n",
      "[[1 1 1]\n",
      " [1 1 6]\n",
      " [7 8 1]\n",
      " [1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "x1=x.copy() #把向量複製一份，免得修改到原始結構\n",
    "x1[x1>8]=1 #將大於8的值的全部修改為1\n",
    "print(x1)\n",
    "\n",
    "x2=x.copy() #把向量複製一份，免得修改到原始結構\n",
    "x2[(x2>5)&(x2<=8)]=1  #將大於5且小於等於8的值的全部修改為1\n",
    "print(x2)\n",
    "\n",
    "x2=x.copy() #把向量複製一份，免得修改到原始結構\n",
    "x2[(x2<=5)|(x2>8)]=1  #將小於等於5或大於8的值的全部修改為1\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "使用numpy的最大好處在於幾乎你所能聽過的各種的基礎函數操作都有一個對應的numpy版本，搭配這些numpy版的函數，可以用來進行對於向量內容的快速修改。我們在此會來介紹一些常用的函數，首先是最單純的使用+(加) -(減) *(乘) /(除)運算符號。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"../images/matrix-subtraction.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "(4, 3)\n",
      "[[ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [12 13 14]\n",
      " [15 16 17]]\n",
      "[[-4 -3 -2]\n",
      " [-1  0  1]\n",
      " [ 2  3  4]\n",
      " [ 5  6  7]]\n",
      "[[0.5 1.  1.5]\n",
      " [2.  2.5 3. ]\n",
      " [3.5 4.  4.5]\n",
      " [5.  5.5 6. ]]\n",
      "[[0.5 1.  1.5]\n",
      " [2.  2.5 3. ]\n",
      " [3.5 4.  4.5]\n",
      " [5.  5.5 6. ]]\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "x1=x.copy()\n",
    "x1=x1+5\n",
    "print(x1)\n",
    "\n",
    "x2=x.copy()\n",
    "x2=x2-5\n",
    "print(x2)\n",
    "\n",
    "x3=x.copy()\n",
    "x3=x3*0.5\n",
    "print(x3)\n",
    "\n",
    "x4=x.copy()\n",
    "x4=x4/2\n",
    "print(x4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "除了可以對數值做加減乘除，也可以對形狀相同的向量進行運算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"../images/matrix-multiply-constant.gif\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在基礎運算中，其中關於向量的乘法是需要好好地做個說明。基本上向量的乘法有兩種，一種是點乘，指的是對應位置成員彼此相乘，另一種則是與矩陣乘法相同，又稱之為哈達馬積(hadamard product)。下圖的左方就是標準的點乘，所以第一行第一列的成員只需要乘上另一個向量對應的一行第一列即可(1*3)。至於完整的矩陣乘法，則是向量的第一列乘上列一個向量的第一行(1*3+2*4=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"../images/matrix_dot.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "基本上在深度學習中比較常使用的是點乘，你可以用乘法運算子*或是np.multiply來執行點乘計算，至於矩陣乘法則要使用np.matmul。在numpy裡還有一個np.dot函數也是乘法，但是老實說這個函數定義很混亂，隨著不同維度可能是點乘或矩陣乘法，我個人很不建議使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "(2, 2)\n",
      "[[3 2]\n",
      " [4 1]]\n",
      "(2, 2)\n",
      "[[ 3  4]\n",
      " [12  4]]\n",
      "(2, 2)\n",
      "[[ 3  4]\n",
      " [12  4]]\n",
      "(2, 2)\n",
      "[[11  4]\n",
      " [25 10]]\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "u=np.array([[1,2],[3,4]])\n",
    "v=np.array([[3,2],[4,1]])\n",
    "print(u)\n",
    "print(u.shape)\n",
    "print(v)\n",
    "print(v.shape)\n",
    "\n",
    "\n",
    "x2=u*v\n",
    "print(x2)\n",
    "print(x2.shape)\n",
    "\n",
    "x3=np.multiply(u,v)\n",
    "print(x3)\n",
    "print(x3.shape)\n",
    "\n",
    "x4=np.matmul(u,v)\n",
    "print(x4)\n",
    "print(x4.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "另一個有時會概念搞混的函數是meshgrid，它並不是乘法，但是當我們輸入兩個向量時，它會返回兩個新的向量，代表以這兩個向量為座標軸的採樣點。所以兩個長度為3的向量經過meshgrid處理後，會返回兩個長度皆為3*3的向量，它意味著向量長度的相乘，而非實際內容值的相乘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1, 2, 3],\n",
      "       [1, 2, 3],\n",
      "       [1, 2, 3]]), array([[4, 4, 4],\n",
      "       [5, 5, 5],\n",
      "       [6, 6, 6]])]\n"
     ]
    }
   ],
   "source": [
    "u=np.array([1,2,3])\n",
    "v=np.array([4,5,6])\n",
    "\n",
    "x=np.meshgrid(u,v)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "此外，常用的幾何運算一個都沒少，像是:\n",
    "np.sqrt()開根號\n",
    "np.log()開自然底數log\n",
    "np.exp()回傳對數\n",
    "np.abs()取絕對值\n",
    "np.sin()取sin\n",
    "np.cos()取cos\n",
    "...族繁不及備載"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在這邊值得一提的是彙總函數，雖然它的外觀和一般彙總沒啥兩樣，但是它最強大之處在於我們可以根據指定的軸面進行彙總，甚麼意思呢，我們直接看結果!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "(4, 3)\n",
      "78\n",
      "()\n",
      "[22 26 30]\n",
      "(3,)\n",
      "[ 6 15 24 33]\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "x1=np.sum(x.copy())#不指定軸面，表示全部都加總\n",
    "print(x1)\n",
    "print(x1.shape)\n",
    "\n",
    "x2=np.sum(x.copy(),0) #指定從第0個軸做匯總，所以第0軸消失，結果長度為3\n",
    "print(x2)\n",
    "print(x2.shape)\n",
    "\n",
    "x3=np.sum(x.copy(),1) #指定從第1個軸做匯總，所以第1軸消失，結果長度為4\n",
    "print(x3)\n",
    "print(x3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"../images/array_sum.png\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在彙總函數指定的第二個參數指的是計算的軸面，若不指定則表示全體。如果指定為0，表示只針對第0軸的方向作加總，由於第0軸被加總掉了自然就消失了，所以結果長度為3等於原先第1軸的長度。反之如果指定為1，表示只針對第1軸的方向作加總，由於第1軸被加總掉了自然就消失了，所以結果長度為4等於原先第0軸的長度。在深度學習中非常常根據指定軸面做計算，為了避免誤解，你會發現不管是cntk,tensorflow, pytorch它們內置函數前面都多了reduce_，原本是np.mean, np.sum...都變成了reduce_mean, reduce_sum...兩者意義是一樣的。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "這堂課我們就以深度學習分類任務中非常重要的softmax函數作為結尾，他表示是將向量取指數後在重新計算占比，你是否知道該如何撰寫對應的函數呢??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.2 3.  4.  2.3]\n",
      "[0.0188365  0.01395442 0.22947558 0.62377929 0.1139542 ]\n"
     ]
    }
   ],
   "source": [
    "def softmax(a):\n",
    "    a1=np.exp(a)\n",
    "    return a1/np.sum(a1)\n",
    "\n",
    "x1=np.array([0.5,0.2,3,4,2.3])\n",
    "print(x1)\n",
    "\n",
    "x2=softmax(x1)\n",
    "print(x2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
