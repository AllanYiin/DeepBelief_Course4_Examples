{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自編碼器Auto-Encoder  (pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###測試於pytorch 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "首先引用所有需要的包，其中pickle是用來讀取或是儲存二進位檔(我已經事先將Minist數據處理成二進位檔)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import codecs\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "use_cuda=True"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "將mnist數據進行轉換，請注意，在pytorch不需要將output轉為onehot，而且需要將他轉型為int64，以配合生成LongTensor。對於feature除以255，是為了將像素值控制在0~1之間，這樣收斂比較快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(60000, 784)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "train_data=None\n",
    "test_data=None\n",
    "\n",
    "with open('mnist_train.pkl', 'rb') as f:\n",
    "    train_data = pickle.load(f)\n",
    "    print(len(train_data))\n",
    "with open('mnist_test.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "    print(len(test_data))\n",
    "    \n",
    "def parse_mnist(data):\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    for row in data:\n",
    "        labels.append(row[-1].astype(np.int64))\n",
    "        features.append(row[:-1].astype(np.float32)/255.0)\n",
    "    return np.asarray(features),np.asarray(labels)\n",
    "\n",
    "features,labels=parse_mnist(train_data)\n",
    "print(features[:3])\n",
    "\n",
    "idxs=np.arange(0,train_data.shape[0])\n",
    "random.shuffle(idxs)\n",
    "idx=0\n",
    "\n",
    "print(features.shape)\n",
    "print(labels.shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 784)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "def get_next_minibatch(minibatch_size):\n",
    "    global idxs,idx\n",
    "    x_features=[]\n",
    "    y_labels=[]\n",
    "    while len(x_features)<minibatch_size:\n",
    "        x_features.append(features[idxs[idx]])\n",
    "        y_labels.append(labels[idxs[idx]])\n",
    "        idx+=1\n",
    "        if idx>=len(idxs):\n",
    "            idx=0\n",
    "            random.shuffle(idxs)\n",
    "    return np.asarray(x_features).astype(np.float32),np.asarray(y_labels).astype(np.float32)\n",
    "\n",
    "features_x,labels_y=get_next_minibatch(3)\n",
    "print(features_x.shape)\n",
    "print(labels_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSPgQSPgQ6F87rjU5dRj2oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba5996fbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=Image.fromarray(np.reshape(features[0,:]*255,(28,28)).astype(np.uint8))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n",
    "\n",
    "print(labels[0,:])\n",
    "print(np.argmax(labels[0,:]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "以下我設計了三種autoencoder結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.d1 = nn.Linear(784, 512)\n",
    "        self.d2 = nn.Linear(512, 256)\n",
    "        self.d3 = nn.Linear(256, 128)\n",
    "        self.d4 = nn.Linear(128, 64)\n",
    "        self.d5 = nn.Linear(64, 32)\n",
    "        self.d6 = nn.Linear(32, 64)\n",
    "        self.d7 = nn.Linear(64, 128)\n",
    "        self.d8 = nn.Linear(128, 256)\n",
    "        self.d9 = nn.Linear(256, 512)\n",
    "        self.d10 = nn.Linear(512, 784)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x = F.relu(self.d2(x))\n",
    "        x = F.relu(self.d3(x))\n",
    "        x = F.relu(self.d4(x))\n",
    "        x = self.d5(x)\n",
    "        x = F.relu(self.d6(x))\n",
    "        x = F.relu(self.d7(x))\n",
    "        x = F.relu(self.d8(x))\n",
    "        x = F.relu(self.d9(x))\n",
    "        x = F.relu(self.d10(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder1, self).__init__()\n",
    "        self.d1 = nn.Linear(784, 512)\n",
    "        self.d2 = nn.Linear(512, 256)\n",
    "        self.d3 = nn.Linear(256, 128)\n",
    "        self.d4 = nn.Linear(128, 64)\n",
    "        self.d5 = nn.Linear(64, 32)\n",
    "        self.d6 = nn.Linear(32, 64)\n",
    "        self.d7 = nn.Linear(64, 128)\n",
    "        self.d8 = nn.Linear(128, 256)\n",
    "        self.d9 = nn.Linear(256, 512)\n",
    "        self.d10 = nn.Linear(512, 784)\n",
    "        self.b1=nn.BatchNorm1d(num_features=512)\n",
    "        self.b2=nn.BatchNorm1d(num_features=256)\n",
    "        self.b3=nn.BatchNorm1d(num_features=128)\n",
    "        self.b4=nn.BatchNorm1d(num_features=64)\n",
    "        self.b5=nn.BatchNorm1d(num_features=32)\n",
    "        self.b6=nn.BatchNorm1d(num_features=64)\n",
    "        self.b7=nn.BatchNorm1d(num_features=128)\n",
    "        self.b8=nn.BatchNorm1d(num_features=256)\n",
    "        self.b9=nn.BatchNorm1d(num_features=512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x =self.b1(x)\n",
    "        x = F.relu(self.d2(x))\n",
    "        x =self.b2(x)\n",
    "        x = F.relu(self.d3(x))\n",
    "        x =self.b3(x)\n",
    "        x = F.relu(self.d4(x))\n",
    "        x =self.b4(x)\n",
    "        x = self.d5(x)\n",
    "        x =self.b5(x)\n",
    "        x = F.relu(self.d6(x))\n",
    "        x =self.b6(x)\n",
    "        x = F.relu(self.d7(x))\n",
    "        x =self.b7(x)\n",
    "        x = F.relu(self.d8(x))\n",
    "        x =self.b8(x)\n",
    "        x = F.relu(self.d9(x))\n",
    "        x =self.b9(x)\n",
    "        x = F.relu(self.d10(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class autoencoder2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder2, self).__init__()\n",
    "        self.d1 = nn.Linear(784, 512)\n",
    "        self.d2 = nn.Linear(512, 256)\n",
    "        self.d3 = nn.Linear(256, 128)\n",
    "        self.d4 = nn.Linear(128, 64)\n",
    "        self.d5 = nn.Linear(64, 32)\n",
    "        self.d6 = nn.Linear(32, 64)\n",
    "        self.d7 = nn.Linear(64, 128)\n",
    "        self.d8 = nn.Linear(128, 256)\n",
    "        self.d9 = nn.Linear(256, 512)\n",
    "        self.d10 = nn.Linear(512, 784)\n",
    "        self.b1=nn.BatchNorm1d(num_features=512)\n",
    "        self.b2=nn.BatchNorm1d(num_features=256)\n",
    "        self.b3=nn.BatchNorm1d(num_features=128)\n",
    "        self.b4=nn.BatchNorm1d(num_features=64)\n",
    "        self.b5=nn.BatchNorm1d(num_features=32)\n",
    "        self.b6=nn.BatchNorm1d(num_features=64)\n",
    "        self.b7=nn.BatchNorm1d(num_features=128)\n",
    "        self.b8=nn.BatchNorm1d(num_features=256)\n",
    "        self.b9=nn.BatchNorm1d(num_features=512)\n",
    "        self.drop1=nn.Dropout1d(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x =self.b1(x)\n",
    "        x = F.relu(self.d2(x))\n",
    "        x =self.b2(x)\n",
    "        x = self.drop1(x)\n",
    "        x = F.relu(self.d3(x))\n",
    "        x =self.b3(x)\n",
    "        x = F.relu(self.d4(x))\n",
    "        x =self.b4(x)\n",
    "        x = self.d5(x)\n",
    "        x =self.b5(x)\n",
    "        x = F.relu(self.d6(x))\n",
    "        x =self.b6(x)\n",
    "        x = F.relu(self.d7(x))\n",
    "        x =self.b7(x)\n",
    "        x = F.relu(self.d8(x))\n",
    "        x =self.b8(x)\n",
    "        x = F.relu(self.d9(x))\n",
    "        x =self.b9(x)\n",
    "        x = F.relu(self.d10(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type autoencoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 100... Loss: 0.0655...\n",
      "Epoch: 1/2... Step: 200... Loss: 0.0682...\n",
      "Epoch: 1/2... Step: 300... Loss: 0.0653...\n",
      "Epoch: 1/2... Step: 400... Loss: 0.0574...\n",
      "Epoch: 1/2... Step: 500... Loss: 0.0552...\n",
      "Epoch: 1/2... Step: 600... Loss: 0.0589...\n",
      "Epoch: 1/2... Step: 700... Loss: 0.0477...\n",
      "Epoch: 1/2... Step: 800... Loss: 0.0506...\n",
      "Epoch: 1/2... Step: 900... Loss: 0.0553...\n",
      "Epoch: 1/2... Step: 1000... Loss: 0.0565...\n",
      "Epoch: 1/2... Step: 1100... Loss: 0.0496...\n",
      "Epoch: 1/2... Step: 1200... Loss: 0.0445...\n",
      "Epoch: 1/2... Step: 1300... Loss: 0.0543...\n",
      "Epoch: 1/2... Step: 1400... Loss: 0.0467...\n",
      "Epoch: 1/2... Step: 1500... Loss: 0.0539...\n",
      "Epoch: 1/2... Step: 1600... Loss: 0.0510...\n",
      "Epoch: 1/2... Step: 1700... Loss: 0.0460...\n",
      "Epoch: 1/2... Step: 1800... Loss: 0.0500...\n",
      "Epoch: 2/2... Step: 100... Loss: 0.0441...\n",
      "Epoch: 2/2... Step: 200... Loss: 0.0504...\n",
      "Epoch: 2/2... Step: 300... Loss: 0.0450...\n",
      "Epoch: 2/2... Step: 400... Loss: 0.0411...\n",
      "Epoch: 2/2... Step: 500... Loss: 0.0405...\n",
      "Epoch: 2/2... Step: 600... Loss: 0.0451...\n",
      "Epoch: 2/2... Step: 700... Loss: 0.0450...\n",
      "Epoch: 2/2... Step: 800... Loss: 0.0472...\n",
      "Epoch: 2/2... Step: 900... Loss: 0.0399...\n",
      "Epoch: 2/2... Step: 1000... Loss: 0.0474...\n",
      "Epoch: 2/2... Step: 1100... Loss: 0.0452...\n",
      "Epoch: 2/2... Step: 1200... Loss: 0.0413...\n",
      "Epoch: 2/2... Step: 1300... Loss: 0.0463...\n",
      "Epoch: 2/2... Step: 1400... Loss: 0.0449...\n",
      "Epoch: 2/2... Step: 1500... Loss: 0.0431...\n",
      "Epoch: 2/2... Step: 1600... Loss: 0.0484...\n",
      "Epoch: 2/2... Step: 1700... Loss: 0.0441...\n",
      "Epoch: 2/2... Step: 1800... Loss: 0.0444...\n"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "問題\n",
    "(1)為何最中間層的活化函數為None(還有哪些選擇呢?)\n",
    "(2)最後一層的活化函數你覺得relu,sigmoid,leaky relu哪效果比較好呢?\n",
    "(3)三種自編碼器哪一種效果比較好(有沒有和預期不同的地方)\n",
    "(4)如果數值正規化方式改為減127.5除以127.5，請問模型結構該如何調整呢?\n",
    "(5)如果是你 ，還可以如何修改網路結構讓效果更好呢?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下來我們比對一下輸入與輸出的差異"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 784)\n",
      "(28, 28)\n",
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24a0c1bd550>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADFCAYAAACfOaMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADBlJREFUeJzt3Wtozv8fx3GXsc35OHMaWhjmlFO7JeyGHMJywyFKSSFW\n3JHSkhAJITe5IceQRLshESOnOZPDnG0zM4fNzjbX/8Zf/f7xevdz7X9d2948Hzefadf3N/P+fWvv\nPp9AMBhsAgDwoWlDPwAA4PcxtAHAEYY2ADjC0AYARxjaAOAIQxsAHGFoA4AjzSL9AYFAgEVwAKiD\nYDAY+Lnxpg0AjjC0AcARhjYAOMLQBgBHGNoA4AhDGwAcYWgDgCMMbQBwhKENAI4wtAHAEYY2ADjC\n0AYARxjaAOAIQxsAHGFoA4AjDG0AcIShDQCOMLQBwBGGNgA4wtAGAEcY2gDgCEMbABxp1tAPAODv\nFRUVJXttba3sgUBA9mAwGLZnaux40wYARxjaAOAIQxsAHGFoA4AjDG0AcITtEeAvEur2RVpamuz9\n+/eXPT4+XvbmzZvL3qyZHkFlZWWy5+TkyP7gwQPZX716JXtpaansxcXFsjcmvGkDgCMMbQBwhKEN\nAI4wtAHAEYY2ADjC9kgddejQQfZFixbJvnnz5kg+Tshu3rwp+/Hjx2W/fPmy7BcvXgzbMyF0Xbp0\nkb2wsFD2BQsWyD5u3DjZhw4dKntCQoLs1pkh1nZKSUmJ7OXl5bIPHz5c9qSkJNlv3bol++3bt2Vn\newQAEFYMbQBwhKENAI4wtAHAEYY2ADgSiPSND4FAwPWVEosXL5Z91apVsvfu3Tukr299/799+ya7\nddOH1auqqmSPiYn5jaf7R01NjewrV66Ufffu3bL/TTeM1Ifx48fLPnr0aNknTJgg+6hRo2S3fk6+\nfv0qe25uruzWVsb3799lb9mypeytWrUK6XOvX78ue1ZWluyvX7+W3TrDJNKCweAvh8Xwpg0AjjC0\nAcARhjYAOMLQBgBHGNoA4Ahnj/yQnJws+5YtW2S3fottndHx5MkT2U+cOCH7o0ePZO/cubPsiYmJ\nsp87d0721NRU2S0pKSmy79y5U/bDhw/LXlRUFNLn4r+s7//gwYNlHzZsmOy9evWS/cuXL7I/e/ZM\nduvn882bN7JXVlbKbt1o069fP9mtG3OsG3msbt2Y01BbIqHgTRsAHGFoA4AjDG0AcIShDQCOMLQB\nwBG2R36wbpyxtkSWLFki+549e2S3zu4I1YsXL2S3zliwHDp0KKQ/f+HCBdmXL18u+40bN2SfM2eO\n7FevXg3pef421taEdXONdbOStSVibYNYN7/cv39fdmv7wtrWsLZE2rZtK7u1PWX9+7LOurG2VuLj\n42V///697A2BN20AcIShDQCOMLQBwBGGNgA4wtAGAEfYHvnh5MmTsqenp8seHR0te7i2RBpKXFyc\n7Na2jMW6wSc2NjbkZ4J9hkbr1q1lt26WsbYgrO2RnJwc2Z8/fy57YWGh7NbPlbXFsX79etmPHj0q\ne2lpqezW9khtba3s1k06jQlv2gDgCEMbABxhaAOAIwxtAHCEoQ0AjrA98sPLly9l//z5s+zWmRvH\njh2T/d27d3V7sAiZOHGi7Bs2bJB9xIgRsldUVMi+bds22T3cDNIYWVsWJSUlsrdv3152a6vE2r44\nc+aM7H379pW9R48eslvbRAMHDpR96tSpslvP//HjR9mLi4tlt7a8qqqqZG9MeNMGAEcY2gDgCEMb\nABxhaAOAIwxtAHCE7ZEfrK0G6+aO1NRU2TMzM2WfNGmS7AUFBf/+cP+HadOmyX7gwAHZrZt6Kisr\nZZ89e7bsp06d+o2nw8+sMzqsG2e6desmu3XmhnWGibVtMn/+fNmtrQzr5ycpKUl266aY6upq2fPy\n8mR/8+aN7Nb21+3bt2W3tnEaE960AcARhjYAOMLQBgBHGNoA4AhDGwAcCVi/ZQ7bBwQCkf2ACGvX\nrp3sly5dkj05OVn2srIy2bdv3y77pk2bZC8vL5fdOqvh+PHjsltnWTx9+lT28ePHy97YzlT5U6Wk\npMg+duxY2Xv27Cm7tT1i/TzExMTIbt3cZPWoqCjZrX8X9+/fl93a8rK2SqybeqybdyI9D0MVDAZ/\n+QvjTRsAHGFoA4AjDG0AcIShDQCOMLQBwBGGNgA4wspfHQ0YMED21atXy24dvGOxVp72798ve0ZG\nhuzWAT4PHz6U3Xr+06dPy4760aFDB9knT54su3VAk3UwVJcuXWS3Vlg7deoku7VSaB3E9OjRI9mt\ng9rOnj0r++PHj2X/9OmT7F6w8gcAzjG0AcARhjYAOMLQBgBHGNoA4AjXjdWR9dvqBQsWyG79Nnzr\n1q2yDxkyRPbNmzf/+8P9j2vXrsm+YsUK2a9evRrS10f9sK7Nunv3ruytW7eWvaamRnZrO8XaNune\nvbvs1sFQ1kFP1vaadYCVdb1aTk6O7H8i3rQBwBGGNgA4wtAGAEcY2gDgCEMbABxheyTMrN+G79ix\nQ/aRI0fKPm/evLA8z8WLF2W3tkrgi7UNUlRUJHvTpvo9zdrK+Pjxo+wFBQWyf/36VfYnT57Ibp1J\nYp1tMnz4cNmtM0aysrJkt75vHvCmDQCOMLQBwBGGNgA4wtAGAEcY2gDgCDfX1JMxY8bIbv122zp7\nIVzWrl0r+7p16yL6uQivPn36yG6d9bFs2TLZExMTZU9ISJD9w4cPsufn58teW1sre8eOHWW3btJp\n1kwvvF26dEn2U6dOyZ6bmyt7Y8PNNQDgHEMbABxhaAOAIwxtAHCEoQ0AjnD2SJh17txZ9l27dslu\nbYl8+/ZN9tmzZ8s+YMAA2a0tkYyMDNkrKipk37Jli+yoH9ZNNNHR0bLPmDFDduvnzdrusG5cunPn\njuxv376VPS4uTvbz58/LfuTIEdljYmJk79q1q+zWVkxhYaHs1dXVsjcmvGkDgCMMbQBwhKENAI4w\ntAHAEYY2ADjC9kiYpaenyz569GjZ8/LyZE9LS5M9Ozs7pOd58OCB7AcPHpR91qxZslvbL5WVlSE9\nD+qmtLRU9hYtWoTUre2msrIy2a0zTF6+fCn769evZY+KipLdOgvF2maxvk67du1kt7ZrrBt8PPD7\n5ADwF2JoA4AjDG0AcIShDQCOMLQBwBG2RxrY0qVLZQ91S8Ri3dxhdetsk4kTJ8p+8uTJuj0YQhIb\nGyu7tSXSsmVL2a1tiqqqKtnLy8t/4+n+YZ1tYj1/mzZtZLf+u6yba6wzQ6wtFM9bT7xpA4AjDG0A\ncIShDQCOMLQBwBGGNgA4EggGg5H9gEAgsh/QyKxbt072NWvWyN6+fXvZS0pKwvZMyuDBg2W/d++e\n7NevX5c9JSUlbM+E0A0bNkz2u3fvhvR1Nm3aFNLX+fLli+zW2SB9+/aV3TqTp0ePHrLn5+fLPnfu\nXNlHjRolu3WmSlFRkewNJRgMBn5uvGkDgCMMbQBwhKENAI4wtAHAEYY2ADjC2SNh9vnzZ9krKipk\nT01Nlf3EiRNheyalW7duIf35hISECD0Jfkcg8MsSQZMmTewzNBYuXCj7yJEjZbe2mKybboqLi2WP\ni4uT3fp5s85Isf69WFsi06dPl/1PPBuHN20AcIShDQCOMLQBwBGGNgA4wtAGAEfYHgmz7du3y96v\nXz/Z9+3bJ/uNGzdk37t3r+zWDR3jxo2TfcKECbJbMjMzQ/rzCC/rjKCCggLZc3NzZU9KSpI9MTFR\n9kGDBslubX1YN9TU1NTIXlZWJvvz589lt/yJWyIW3rQBwBGGNgA4wtAGAEcY2gDgCEMbABzh5pp6\nYt3cceHCBdm7d+8ue6T/vq5cuSL7lClTZLduMEHDio+Pl33IkCGyJycny25tm1hff+bMmbLv3LlT\ndmtLZMeOHbL/bbi5BgCcY2gDgCMMbQBwhKENAI4wtAHAEbZHGlivXr1kX7RokezWb+2bNtX//7W2\nVjZu3Ch7dna27J8+fZIdfwbrzBDrZhzUD7ZHAMA5hjYAOMLQBgBHGNoA4AhDGwAcYXsEABoptkcA\nwDmGNgA4wtAGAEcY2gDgCEMbABxhaAOAIwxtAHCEoQ0AjjC0AcARhjYAOMLQBgBHIn72CAAgfHjT\nBgBHGNoA4AhDGwAcYWgDgCMMbQBwhKENAI4wtAHAEYY2ADjC0AYARxjaAOAIQxsAHGFoA4AjDG0A\ncIShDQCOMLQBwBGGNgA4wtAGAEcY2gDgCEMbABxhaAOAI/8BwoIonhGmq78AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24a0bb8fd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y=get_next_minibatch(minibatch_size)\n",
    "input=torch.from_numpy(x)\n",
    "input=Variable(input)\n",
    "input=input.cuda()\n",
    "output = model(input)\n",
    "pred=output.cpu().detach().numpy()\n",
    "print(pred.shape)\n",
    "#實際值\n",
    "actual=np.reshape(x[1,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(pred[1,:]*255,(28,28)).astype(np.uint8)\n",
    "print(actual.shape)\n",
    "print(pred.shape)\n",
    "img=Image.fromarray(np.concatenate([actual,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 去噪自編碼器 Denoise AutoEncoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "所謂的去噪自編碼器，輸入值是添加了噪音的數據，但是輸出卻希望他能還原回原來乾淨的數據，這個做法等於是強迫模型自己找出噪音與真實數據間的差異進而分離純化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/denoise.jpg\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "所以唯一需要修正之處在於產生添加噪音的輸入值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24a0bd29ba8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADFCAYAAACfOaMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFKK0AQpR2gCFKG2AQpQ2QCFKG6CQ/wK0/GbcEsbjXQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24a0bb6c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_next_noise_minibatch(minibatch_size):\n",
    "    global idxs,idx\n",
    "    x_features=[]\n",
    "    x_noise=[]\n",
    "    while len(x_features)<minibatch_size:\n",
    "        x_features.append(features[idxs[idx]])\n",
    "        x_noise.append(features[idxs[idx]]+np.random.standard_normal(784)*0.005)\n",
    "        idx+=1\n",
    "        if idx>=len(idxs):\n",
    "            idx=0\n",
    "            random.shuffle(idxs)\n",
    "    return np.asarray(x_features).astype(np.float32),np.asarray(x_noise).astype(np.float32)\n",
    "\n",
    "features_x,noise_x=get_next_noise_minibatch(3)\n",
    "actual=np.reshape(features_x[0,:]*255,(28,28)).astype(np.uint8)\n",
    "noise=np.reshape(noise_x[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,noise],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "雖然輸入含噪音數據，但是損失函數則需要比對乾淨的原始值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type autoencoder1. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 100... Loss: 0.0632...\n",
      "Epoch: 1/2... Step: 200... Loss: 0.0544...\n",
      "Epoch: 1/2... Step: 300... Loss: 0.0457...\n",
      "Epoch: 1/2... Step: 400... Loss: 0.0390...\n",
      "Epoch: 1/2... Step: 500... Loss: 0.0414...\n",
      "Epoch: 1/2... Step: 600... Loss: 0.0388...\n",
      "Epoch: 1/2... Step: 700... Loss: 0.0375...\n",
      "Epoch: 1/2... Step: 800... Loss: 0.0416...\n",
      "Epoch: 1/2... Step: 900... Loss: 0.0469...\n",
      "Epoch: 1/2... Step: 1000... Loss: 0.0344...\n",
      "Epoch: 1/2... Step: 1100... Loss: 0.0430...\n",
      "Epoch: 1/2... Step: 1200... Loss: 0.0399...\n",
      "Epoch: 1/2... Step: 1300... Loss: 0.0376...\n",
      "Epoch: 1/2... Step: 1400... Loss: 0.0342...\n",
      "Epoch: 1/2... Step: 1500... Loss: 0.0330...\n",
      "Epoch: 1/2... Step: 1600... Loss: 0.0357...\n",
      "Epoch: 1/2... Step: 1700... Loss: 0.0392...\n",
      "Epoch: 1/2... Step: 1800... Loss: 0.0421...\n",
      "Epoch: 2/2... Step: 100... Loss: 0.0325...\n",
      "Epoch: 2/2... Step: 200... Loss: 0.0334...\n",
      "Epoch: 2/2... Step: 300... Loss: 0.0338...\n",
      "Epoch: 2/2... Step: 400... Loss: 0.0364...\n",
      "Epoch: 2/2... Step: 500... Loss: 0.0322...\n",
      "Epoch: 2/2... Step: 600... Loss: 0.0369...\n",
      "Epoch: 2/2... Step: 700... Loss: 0.0310...\n",
      "Epoch: 2/2... Step: 800... Loss: 0.0310...\n",
      "Epoch: 2/2... Step: 900... Loss: 0.0288...\n",
      "Epoch: 2/2... Step: 1000... Loss: 0.0324...\n",
      "Epoch: 2/2... Step: 1100... Loss: 0.0338...\n",
      "Epoch: 2/2... Step: 1200... Loss: 0.0287...\n",
      "Epoch: 2/2... Step: 1300... Loss: 0.0344...\n",
      "Epoch: 2/2... Step: 1400... Loss: 0.0308...\n",
      "Epoch: 2/2... Step: 1500... Loss: 0.0326...\n",
      "Epoch: 2/2... Step: 1600... Loss: 0.0343...\n",
      "Epoch: 2/2... Step: 1700... Loss: 0.0321...\n",
      "Epoch: 2/2... Step: 1800... Loss: 0.0320...\n"
     ]
    }
   ],
   "source": [
    "model1 = autoencoder1()\n",
    "if use_cuda:\n",
    "    model1 = model1.cuda()\n",
    "optimizer = optim.Adam(model1.parameters(), lr=0.01)\n",
    "ceriation = nn.MSELoss()\n",
    "num_epochs=2\n",
    "minibatch_size=32\n",
    "for epoch in range(num_epochs):\n",
    "    mbs=0\n",
    "    rows=0\n",
    "    ave_loss = 0\n",
    "    while rows < train_data.shape[0]:\n",
    "        optimizer.zero_grad()\n",
    "        features_x,noise_x=get_next_noise_minibatch(minibatch_size)\n",
    "        noise, target = torch.from_numpy(noise_x), torch.from_numpy(features_x)\n",
    "        if use_cuda:\n",
    "            noise, target = noise.cuda(), target.cuda()\n",
    "        noise, target = Variable(noise), Variable(target)\n",
    "        out = model1(noise)\n",
    "        loss = ceriation(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if mbs%100==0 and mbs>0:\n",
    "            print(\"Epoch: {}/{}...\".format(epoch+1, num_epochs),\n",
    "                          \"Step: {}...\".format(mbs),\n",
    "                          \"Loss: {:.4f}...\".format(loss.data.item()))\n",
    "        mbs+=1\n",
    "        rows+=minibatch_size\n",
    "        torch.save(model1, 'Models/denoise_autoencoder_pytorch.cnn'.format(epoch))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "比對原始數據、添加噪音數據以及最後模型生成值，可以看到神經網路學會了如何區分噪音與信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24a0014fa58>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAACPCAYAAAAx+oofAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADi5JREFUeJzt3W2Q1fMbx/EWydpqLN2StuSmNJOJpq1oZLDSMMZdeNDU\nDIN4gGkG4+5ZHjDFGHflZjJupilp5QGRMcIYySJUmxkjaouIqEmK9fjz+fv/vn2dc3bPtft+Pft0\n7n7n/M5ec7rO91zfmvb29h4AgBgO6ewDAAAcPIo2AARC0QaAQCjaABAIRRsAAqFoA0AgFG0ACISi\nDQCBULQBIJDDKv0ANTU1/OSyC6upqZHsv7D9+++/JR9ySPHnBL+93/+hhx4q+a+//jqo4/x//HgO\nHDhQeHnq+ZZ6uSv380Us7e3tNf5vfNIGgEAo2gAQSE2lB0bRHonN3x+p9ob/99//O5/bPkjx4/H7\nq/T7O7f9U+n7y22/oLrRHgGA4CjaABAIRRsAAqn4kj/Eluox++Xek3WpHnZuT9YfL7cnnpI6nlRO\nHU9uDzt3iWW5Xw90Pj5pA0AgFG0ACISiDQCB0NNGodQ66FQP25Xaw3Z+ff/Zd2qdee7xu1LXUefe\nPvc7AXQ9fNIGgEAo2gAQCEUbAAKhp41CqdkhuT3UVE+21HXLuaNfU3JnmaRej1LXqTNLRI0cOVJy\nU1OT5L59+0ru1auX5K1bt0r+9ttvJW/YsEHy5s2b/8thlhWftAEgEIo2AARC0QaAQOhpZ2poaJA8\nduxYyVdddVXh7S+77DLJhx9+uOQXXnhB8s033yz5t99+O6jjLJdS51v79l2HHVb8lvN11im5PWI/\nf2PGjJF89dVXS/bn88cff0iura2V/Pzzz0tOnT//zsCff27P3r8TiN4D79evn+Qbb7xR8rRp0yTX\n19dLPvLIIyX7+7G1tVXyJ598Inn48OGSm5ubJW/btu3fDrui+KQNAIFQtAEgEIo2AATCHpHG130u\nXLhQcmNjo+SePXtW9Hi85/rll19W9PFy5c6Pzp01knv93PPn3ym41PPznrT3nFPnr9x7ZJY6S6Wz\n+XdCs2bNkjxu3DjJ3qPesmVL4eX+9/rnn39K3rRpk+SPPvpIckf3tNkjEgCCo2gDQCAUbQAIpNuv\n0x42bJjkjz/+WHJdXZ3kL774QvKKFSskt7W1Sb7iiiskT548WXJq3fLdd98ted68eZLXrl1bePty\ny5094j1Wf765e0B6D9fX0fr581kT69evl+znz3uUvq7+7LPPlpxaV546f7nztF30Hvb48eMlT58+\nXfJ5550nuXfv3pJXr14tedWqVZL9fA4cOFDyGWecIfmYY46RfPrpp0tuaWkpvP+OwCdtAAiEog0A\ngVC0ASCQbtfTHjx4sGRfx/v7779LPuWUUyT//PPPkvft21f4eE888UTh7X1WgrvkkkskL1myRHKl\ne9ql7uFYas/WH3/QoEGS/fXdvXu35JNOOknyzp07Jfv588d7/PHHC2/vPVBfF+znb/HixZI7+juJ\nzubfAVx66aWShw4dKtl79t7DfvnllyW/8847kn1WjK/THzFihGR/f+3Zs0eyr8vvDHzSBoBAKNoA\nEAhFGwAC6XY9be9B+jrQH3/8UfKuXbskp3rYzucp+551zntwixYtkrx8+fKsxy9VajaGX17qLIzU\nuu+jjz5asp+/HTt2SPbvKHzWRGrd+U033ST5kUcekbx//37J/v7w+dqvvvpqjxy5r3/u7JKOdtpp\np0keMmSIZJ9/vXHjRsmvv/665AULFkj2eeU+j7t///6SR40aVXi8v/zyi2T/zqIz8EkbAAKhaANA\nIBRtAAik2/W0UwYMGCD5/vvvl3zLLbdk3d/KlSsl7927V7LPUvCep/dUO1tqD8Jyz9JI7ZHo1/ce\n5ty5cyXfeuuthbf32ShvvfWWZF+3699R+CwT39PQ5X4HEK2H7Xx+uWefDfLhhx9K/vrrryV7D9vn\nZZ977rmSfd28zx7yPSK9p/7ZZ5/16Gx80gaAQCjaABAIRRsAAul2e0TW1tZKvv766yU/9NBDkn/9\n9VfJxx57rGRfV+33v2bNGsmjR4+W7HvQzZ49W3Jn99BSPepUDzbVc82dp+3zzW+44QbJ8+fPl+zr\n7P07C19n7euEfT63z6Lx8+vfQXz++ec9iuT+/fnr4bM8Kv33XCp//efMmSP5ggsukOzr7JctWyb5\nvffek+x7cvqekxMnTpS8YcMGyU8//bRk/51ER6/TZo9IAAiOog0AgVC0ASCQbtfTdt6D9lkRvkeg\nr+P0Hpz32Hy2gfdQGxoaJG/fvj1xxB2r3OuIS51N4nwPyJdeekmyz2v289fU1CT5/fffl5w6fz7/\n2c9ftHXUHW3q1KmSr7nmGsk+a8b3ZGxtbZU8ZcoUyRMmTJDs89CfeeYZyQ888EDxAXcwetoAEBxF\nGwACoWgDQCDdvqftfB32d999Jzl3tobvKXfddddJfu6557Lur6OletDes01dnpI7L9ovP+644yRv\n3rxZsj+f1Dxt72Gnzl/q78kfPzW7xd8/uXt2VntP3WePzJo1S7LPDvG/T3/+J554omT/HcWLL74o\n+d577z3oY+0M9LQBIDiKNgAEQtEGgEAo2gAQCJsgmLa2NskffPCB5MmTJxfe3oe233HHHZL9xxvV\nrtwb86bkfrGW2pRh9erVkidNmiTZBy75+T7nnHMkp85f6otG5180+iYMqeeb+3jVxjda/v777yX7\npiH+Y5v6+nrJ/vx9oFdzc/N/Os5qwidtAAiEog0AgVC0ASAQetrGBwx5Dzv144bly5dLjtbDdqkf\nf6R+/JL6sU2pt3eXX365ZD8fqR74K6+8Ijl1/nJ/7OK8p56Sen1S1692RxxxhOTBgwdL9h9PeY/b\nNzX49NNPJfvAsIj4pA0AgVC0ASAQijYABNLtB0adeeaZkt99913J3sP1HtnYsWMle4+xd+/ekn2A\nTVeT2wMvlQ+59x60P35LS4vk1Pnr06eP5NT58+fnPevcde+p66d64tW+bnvIkCGS77vvPsm+CYkP\nhNq6davkdevWSV6xYoXkRx99VLJvHFxtGBgFAMFRtAEgEIo2AATS7dZp+xD1pUuXSvYe6KZNmyRP\nnDhR8oIFCyTPnDlT8oABAyT7pgrRpNYlpzaJKHWIv6/b9VkS3uPduHGj5NT5mzFjhuSBAwdK9tkY\nqeMv90bIPpvE+SyT3E07Ku2oo46SfP7550u+8MILJft3Qr5x9muvvSa5f//+kv38jR8/XvLbb7+d\nOOLqU11nFABQiKINAIFQtAEgkC7f066rq5P85JNPSh40aJDk7du3S25sbJTs83+feuopyb4x6cMP\nPyzZ151Gk+pJ525s6/z2PovCe9Des9y2bZtkX8ftG/UuXLhQ8rXXXit52bJlklPnLzXrI7WxsPfA\nvYd94MAByameeLUZN26cZJ/14z1v/07Je9j+etTW1koeMWKE5DFjxkj2313s3Lnz3w67qvBJGwAC\noWgDQCAUbQAIpMv3tH1d7kUXXVR4/blz50retWtX4fX9cu8xeo8tulLnN+f2wM866yzJ06ZNKzye\n3PO3e/duyb7O+c0335Rcag859Xx9nXlq3XW197B9/rXPp/ees88SeeONNySvXbtW8sknnyx53759\nkn22SUNDg+RRo0ZJ9j1CqxGftAEgEIo2AARC0QaAQLp8T3vOnDmFl/sskGeffTbr/ocOHVp4+fr1\n67Pur6tL9cS9Z+vnz3u4fv4WLVokOdVDv/jiiwsv9z0Hp06d+i9HffBSPe1o666dnz+f9XHqqadK\n7tmzp+SvvvpK8po1ayT7/OtevXpJ9r9H76n/9NNPklOzXKoRn7QBIBCKNgAEQtEGgEDiNXQy+Z5y\nzmeJ7N27t/D63gO78847C68/b968wsujS/VgUznF1/F6T9zX5e7Zs6fw8Xwd9KpVqwof/8EHHyy8\nv9wede78cT9ev37unpOV5vOsvcfct29fyT7rw/++Jk2aJLm+vl6y/317D9tfn7a2NslbtmzpEQ2f\ntAEgEIo2AARC0QaAQLp8T3v+/PmSH3vsMcneA/N1wb4OePr06ZJ9loLP/92xY8fBH2wV8h6uz8JI\n9Yz9+i7VE549e7ZkP3/HH3+85Ntuu02y9zCvvPJKyVOmTJHse0r+8MMPkr1HmurRl9rTz531kno9\nK81fr2+++Uaynw9fpz1y5EjJo0ePlux/r94D91kyPrvEv8Pw44uAT9oAEAhFGwACoWgDQCA1le6B\n1dTUdGqTbdiwYZJbWlok+550uXyd9/DhwyX7noXReI/ae6y5szJy328nnHCCZJ9F0a9fP8neQ089\nnp8/X/fr5y+17jrVw87tiadUW0/b9enTR/LMmTMl++vt89N9Hrafb+9J+zzsxYsXS165cmXiiKtL\ne3v7/7xB+KQNAIFQtAEgEIo2AATS5XvabsKECZLvuusuyb6HpPc8ly5dKvn222+XHL2HncvfP75u\nNrVOO/f+GxsbJd9zzz2SU+dvyZIlkn12TKqHnSvV8/Yed2oWSYq/3v6dRGerq6uT3NTUJNl74L4u\n259Pa2ur5ObmZsn79+//T8dZLehpA0BwFG0ACISiDQCBdLueNvKk5j/n9mxTl3tP3C8vdw/YpeZV\np9ZVp65f7j0go+8piWL0tAEgOIo2AARC0QaAQLr8PG2UJrdHmttj9R5ybs889fip+0vJnSeeuv/U\nbJJSb4+uj0/aABAIRRsAAqFoA0Ag9LRRktS6Zpfq4eaui071sHN70rk949zrp443pdrmZaPj8Ukb\nAAKhaANAIBRtAAik4rNHAADlwydtAAiEog0AgVC0ASAQijYABELRBoBAKNoAEAhFGwACoWgDQCAU\nbQAIhKINAIFQtAEgEIo2AARC0QaAQCjaABAIRRsAAqFoA0AgFG0ACISiDQCBULQBIBCKNgAE8g+x\nkbgVmqrOAwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24a0014fac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_features,raw_noise=get_next_noise_minibatch(minibatch_size)\n",
    "input=torch.from_numpy(raw_noise)\n",
    "input=Variable(input)\n",
    "input=input.cuda()\n",
    "output = model1(input)\n",
    "results=output.cpu().detach().numpy()\n",
    "#實際值\n",
    "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
    "noise=np.reshape(raw_noise[0,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,noise,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 變分自編碼器（VAE）"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "變分自編碼器雖然名字叫做自編碼器，但實際上與自編碼器沒有太多關係，相對的，他反而很常被拿來與GAN相提並論，它的目的都是透過一個隱向量的分布來去生成一群樣本。變分自編碼器不管原始樣本的分布是如何，他都強制轉換為一個常態分配的分布，也就是他的作用是用來進行強制分布變換。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class vae_encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vae_encoder, self).__init__()\n",
    "        self.d1 = nn.Linear(784, 512)\n",
    "        self.d2 = nn.Linear(512, 256)\n",
    "        self.d3 = nn.Linear(256, 128)\n",
    "        self.d4 = nn.Linear(128, 64)\n",
    "        self.d5 = nn.Linear(64, 32)\n",
    "        self.d6 = nn.Linear(64, 32)\n",
    "        self.b1=nn.BatchNorm1d(num_features=512)\n",
    "        self.b2=nn.BatchNorm1d(num_features=256)\n",
    "        self.b3=nn.BatchNorm1d(num_features=128)\n",
    "        self.b4=nn.BatchNorm1d(num_features=64)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.d1(x))\n",
    "        x =self.b1(x)\n",
    "        x = F.relu(self.d2(x))\n",
    "        x =self.b2(x)\n",
    "        x = F.relu(self.d3(x))\n",
    "        x =self.b3(x)\n",
    "        x = F.relu(self.d4(x))\n",
    "        x =self.b4(x)\n",
    "        return self.d5(x),self.d6(x)\n",
    "    \n",
    "    \n",
    "class vae_decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vae_decoder, self).__init__()\n",
    "        self.d6 = nn.Linear(32, 64)\n",
    "        self.d7 = nn.Linear(64, 128)\n",
    "        self.d8 = nn.Linear(128, 256)\n",
    "        self.d9 = nn.Linear(256, 512)\n",
    "        self.d10 = nn.Linear(512, 784)\n",
    "        self.b6=nn.BatchNorm1d(num_features=64)\n",
    "        self.b7=nn.BatchNorm1d(num_features=128)\n",
    "        self.b8=nn.BatchNorm1d(num_features=256)\n",
    "        self.b9=nn.BatchNorm1d(num_features=512)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 32)\n",
    "        x = F.relu(self.d6(x))\n",
    "        x =self.b6(x)\n",
    "        x = F.relu(self.d7(x))\n",
    "        x =self.b7(x)\n",
    "        x = F.relu(self.d8(x))\n",
    "        x =self.b8(x)\n",
    "        x = F.relu(self.d9(x))\n",
    "        x =self.b9(x)\n",
    "        x = F.relu(self.d10(x))\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "class vae(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(vae, self).__init__()\n",
    "        self.encoder= vae_encoder()\n",
    "        self.decoder = vae_decoder()\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return mul(std).add_(mu)\n",
    "            #return eps.mul(std).add_(mu)\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x.view(-1, 784))\n",
    "        z = self.reparametrize(mu, logvar)\n",
    "        return self.decoder(z),mu, logvar\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "recon_loss = nn.MSELoss()\n",
    "recon_loss.size_average = False\n",
    "def vae_loss(recon_x, x, mu, logvar):\n",
    "    BCE = recon_loss(recon_x, x.view(-1, 784))\n",
    "\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    return BCE+KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type vae. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type vae_encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:250: UserWarning: Couldn't retrieve source code for container of type vae_decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 100... Loss: 0.1003...\n",
      "Epoch: 1/2... Step: 200... Loss: 0.0889...\n",
      "Epoch: 1/2... Step: 300... Loss: 0.0853...\n",
      "Epoch: 1/2... Step: 400... Loss: 0.0729...\n",
      "Epoch: 1/2... Step: 500... Loss: 0.0680...\n",
      "Epoch: 1/2... Step: 600... Loss: 0.0671...\n",
      "Epoch: 1/2... Step: 700... Loss: 0.0760...\n",
      "Epoch: 1/2... Step: 800... Loss: 0.0738...\n",
      "Epoch: 1/2... Step: 900... Loss: 0.0747...\n",
      "Epoch: 1/2... Step: 1000... Loss: 0.0730...\n",
      "Epoch: 1/2... Step: 1100... Loss: 0.0697...\n",
      "Epoch: 1/2... Step: 1200... Loss: 0.0743...\n",
      "Epoch: 1/2... Step: 1300... Loss: 0.0783...\n",
      "Epoch: 1/2... Step: 1400... Loss: 0.0752...\n",
      "Epoch: 1/2... Step: 1500... Loss: 0.0672...\n",
      "Epoch: 1/2... Step: 1600... Loss: 0.0705...\n",
      "Epoch: 1/2... Step: 1700... Loss: 0.0784...\n",
      "Epoch: 1/2... Step: 1800... Loss: 0.0716...\n",
      "Epoch: 2/2... Step: 100... Loss: 0.0663...\n"
     ]
    }
   ],
   "source": [
    "model2 = vae()\n",
    "if use_cuda:\n",
    "    model2 = model2.cuda()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs=2\n",
    "minibatch_size=32\n",
    "for epoch in range(num_epochs):\n",
    "    mbs=0\n",
    "    rows=0\n",
    "    while rows < train_data.shape[0]:\n",
    "        optimizer.zero_grad()\n",
    "        x,y=get_next_minibatch(minibatch_size)\n",
    "        x = torch.from_numpy(x.astype(np.float32))\n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "        x= Variable(x)\n",
    "        z_vae, mu, logvar = model2(x)\n",
    "        loss = vae_loss(z_vae, x, mu, logvar)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if mbs%100==0 and mbs>0:\n",
    "            print(\"Epoch: {}/{}...\".format(epoch+1, num_epochs),\n",
    "                          \"Step: {}...\".format(mbs),\n",
    "                          \"Loss: {:.4f}...\".format(loss.data.item()))\n",
    "        mbs+=1\n",
    "        rows+=minibatch_size\n",
    "        torch.save(model2, 'Models/vae_pytorch.cnn'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ba0fd8f7f0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAADFCAYAAACfOaMVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADMZJREFUeJzt3V1o1nUfx/Fd2Xxsm07TnKJNZUrhKIXRgUhaUFgpeRAD\nTwpFO1ArUk9M8EAoUoIID0x6UPREPKigxMRCUGy5tmoLLXXa3HQ1H+azmw+7D+4bbqjP526/6762\n+Z3v1+GHcV0/L7cPf7i+fH+Zzs7OPABADPf19gEAAF1HaQNAIJQ2AARCaQNAIJQ2AARCaQNAIJQ2\nAARyf3e/QSaTYRAcALLQ2dmZ+WvGkzYABEJpA0AglDYABEJpA0Ag3f5FJICel8n87furvLy8vDy3\nIM79fOrr5Oo8DgvueNIGgFAobQAIhNIGgEAobQAIhNIGgECYHullb775psw3bNgg823btsl8zZo1\nMj958mRW50IM/fr1k/ngwYOTft5NdziTJ0+W+dmzZ2VeXFws81u3biXljY2NMr927ZrMb9++nZQ7\nuZp+yQWetAEgEEobAAKhtAEgEEobAAKhtAEgEKZHetmMGTNk7r6VXrBggcw3bdokc6ZHYnHTHXfu\n3JF5fn6+zFOnGgYOHCjzMWPGyHzkyJEyHzdunMwnTJgg8+rqaplfuXJF5sOHD5e5mzZpb2+XueOm\nRNzr9waetAEgEEobAAKhtAEgEEobAAKhtAEgEKZHgqmvr5f5iRMnevgk6A5uJ8Z99+nnq46OjqTX\nuf9+/Sc/YMAAmRcUFCS9r5vu+PXXX5Ne58aNGzJ30yBuWsZ9bm4ax31u7B4BAGSF0gaAQChtAAiE\n0gaAQChtAAiE6ZEeUlZWJvPy8nKZu2mQOXPmyLy5uTm7gyGE1N0jbmrC7RgZNWpUUl5UVCRztzPk\n1KlTMm9tbZW5mypJvaHGTcvcvHlT5hHwpA0AgVDaABAIpQ0AgVDaABAIpQ0AgTA9kmPu2/Zdu3bJ\nvLS0VOa7d++WeVNTU3YHQ2hu94WbEiksLJT51KlTZf7ss8/KvH///jJ30yN79+6VeVtbm8z//PNP\nmbtpmdRdH26qxE3duBtq3PuyewQA8D9R2gAQCKUNAIFQ2gAQCKUNAIEwPZIl9+3z0qVLZe6mRGpq\namS+aNGi7A6GPslNjwwaNEjmFRUVMn/qqadk7qaeLl68KHM3DVVVVSXz06dPy9xNiThuusPtGOnX\nr5/M3dSHex03hdIbUyU8aQNAIJQ2AARCaQNAIJQ2AARCaQNAIEyPZMlNiaxevVrm7e3tMl+5cqXM\nuYnm3uR2iQwZMkTmJSUlMp82bZrMx40bJ3N3I4y7QengwYMydzfRuJtiUqcv3OeTOoXipkrclI7j\npkrc6+RiqoQnbQAIhNIGgEAobQAIhNIGgEAobQAIhOmRf/DII4/IfPny5TJ3UyKrVq2S+bfffpvd\nwdAnuZ02Y8aMkfnLL78s8ylTpiS9r7txZs+ePTJvaWmRufv9T+V2gLjpETcN4j5Pd/OOm+64fv26\nzK9cuSLzjo6OpNdPwZM2AARCaQNAIJQ2AARCaQNAIJQ2AATC9Mh/FBYWyvyrr76SudvhcPToUZl/\n8MEH2R2sh40dO1bmTU1NPXySvs3tphg4cKDM3c1H48ePl7mbUkjdJdLY2Chzt3PDcf/e/v37y7yg\noEDmxcXFMh82bJjMhw4dKnN3k46b0nGfm3P+/Pmkn0/BkzYABEJpA0AglDYABEJpA0AglDYABHLP\nTY+4nQZvvfWWzN2UiNux8N5772V3sP+T+/Z8/vz5Mq+srJS5m1JI/fbc3cjz448/Jr1OX5V6Q82s\nWbNk/vDDD8v8woULMq+rq0v6ecft+nDTL8OHD5f5o48+KvPHHntM5u7vsba2VuZuisZNSbnpFPf/\n8ttvv8k89fNMwZM2AARCaQNAIJQ2AARCaQNAIJQ2AARyz02PLFmyROYrVqxIep13331X5ps2bUo+\nUwo3JbJ161aZP/fcczl53wkTJiT9/Jdffinz7du3y/zDDz+U+bFjx5LeNwo3fTFz5kyZu2kH9zo1\nNTUyT50ecbtB3M0vZWVlMp89e7bMn376aZk7Z8+elbmbCnM7Rtz0zujRo2Xudry0tbXJ/PDhwzJP\n3dmi8KQNAIFQ2gAQCKUNAIFQ2gAQCKUNAIH02ekR9+2w2+HgfPfddzLfuHFj8plS5GpK5MCBAzLf\nsGGDzFtaWrpwun/2xhtvyPy1116T+YIFC2TuvrW/detWdge7S7jpixEjRsjc7YQ5c+aMzKuqqmR+\n/PjxLpzuvwYNGiTzJ598UubPPPOMzKdOnSpzd7OMuylp//79Mm9oaJC56wG3s2XixIkydztMqqur\nZe5uwjp37pzMU/CkDQCBUNoAEAilDQCBUNoAEAilDQCBUNoAEEifHfl7//33Ze6u37p48aLM586d\nK3O3uCaVG3lKHe3bsmWLzJcuXSrzq1evduF02XPXmb3zzjsyX7Vqlczd9W3Lly/P7mA9zI2cjRw5\nUuZuNM4tbmpubpa5G+27fv26zN3iKTeaOGPGDJmXlJQkvc7JkydlvmvXLpm7RWRu4ZVbAJWfny/z\ny5cvy9yNYrr/r507d8o8F3jSBoBAKG0ACITSBoBAKG0ACITSBoBA+uz0iJuacItffv75Z5nnakrE\neeGFF2Seek3YRx99JPPunhJJ9cUXX8jcLZhy/49RpkcymYzMJ02aJPOOjg6Zu9/bGzduJL2OmxJx\nUy5u6sMt7HJ/L6dOnZL5vn37ZO6mRNyUl7tuzJ3TTX246Rrn0qVLMi8oKJC5m05JwZM2AARCaQNA\nIJQ2AARCaQNAIJQ2AATSZ6dHHDdNMW/evB4+yb+5KQLn0KFDMv/hhx9ycZxuV1FRIXO3C6Kurq47\nj5MzbkrETTW4qQM33eF+3k0jDB48WObuc3bTI+66sQEDBsjcTYm46ayvv/5a5u7fe+fOHZk7xcXF\nMh81apTM3ed2+vRpmbe2tso8F1MiDk/aABAIpQ0AgVDaABAIpQ0AgVDaABDIPTc94r4dfvHFF2X+\nySefdOdx8j7//HOZr1mzRubl5eUyd7sUvv/+++wO1kVTpkyR+euvvy7zl156Ken1165dm3qku4qb\nKnFTEKWlpTJ3OzTcFITbPeJ2YrgpkQceeEDmf/zxh8zd7pGmpiaZu8+nsLBQ5u6c7iagOXPmyNz9\n3robgmpra2VeVVUlc/fvygWetAEgEEobAAKhtAEgEEobAAKhtAEgkD47PeJ2cUybNk3mb7/9tszd\njSGffvppVuf6K7db45tvvpH57NmzZV5ZWSnz33//Xebu23+3C2XFihVJ7+u+/XdeeeUVmX/22WdJ\nr9Nb3O+Jm/poaWmR+ZEjR2TudrY89NBDMn/11Vdl3tjYKHN3Y8sTTzwhc7fTo6GhQebu98rtGHE7\nW0pKSmTuuJ0qbkrEnd9Nj7jP89q1a104XXZ40gaAQChtAAiE0gaAQChtAAiE0gaAQDLuW++cvUEm\n071vYLgdC24qY/r06TJ3n09bW5vMz58/L/ONGzfK3HG7ERYvXpz0Ou4GDTfV4L5VHzJkSNL7uptK\n3JTOjh07ZN7dv5/dzd0UU1RUJPOFCxfK3E1xTJw4UeZuR4fj/t/dDTVut4bLb968mfTz7gYf9/fl\nbpZx+dGjR2VeU1OTlLvztLe3yzz197mzs/NvHxBP2gAQCKUNAIFQ2gAQCKUNAIFQ2gAQSJ+dHnHc\nVMm6detkvmzZsu48ThibN2+W+YULF2S+fv16mZ87dy5nZ4rATUe4qYzJkyfL3N3443aSlJWVydzd\nROOmR9z0i7sZ5/bt2zJP7Rl3080vv/wi8/r6epm7KSa3Y8Tt6nH/XncDkZvOSsX0CAAER2kDQCCU\nNgAEQmkDQCCUNgAEcs9NjzjuW353g8bzzz8v88cffzxnZ8qFjz/+WObNzc1Jr+O+DY++G6S3uBtV\n3FSJuynG7R5xu2vczUcPPvigzN3OkMOHD8t86NChMv/pp59k7m7McT/vdv64m4DcDhA35ZI6/eKm\nR1yfsHsEAO4xlDYABEJpA0AglDYABEJpA0AgTI8AdxE3deC43SDu79pNQ7mfd1NDqdMRueqZXL1+\nb50/FdMjABAcpQ0AgVDaABAIpQ0AgVDaABAI0yMAcJdiegQAgqO0ASAQShsAAqG0ASAQShsAAqG0\nASAQShsAAqG0ASAQShsAAqG0ASAQShsAAqG0ASAQShsAAqG0ASAQShsAAqG0ASAQShsAAqG0ASAQ\nShsAAqG0ASAQShsAAqG0ASAQShsAAqG0ASAQShsAAqG0ASAQShsAAqG0ASAQShsAAsl0dnb29hkA\nAF3EkzYABEJpA0AglDYABEJpA0AglDYABEJpA0AglDYABEJpA0AglDYABEJpA0AglDYABEJpA0Ag\nlDYABEJpA0AglDYABEJpA0AglDYABEJpA0AglDYABEJpA0Ag/wJsKrVTugQcwQAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba0fd8f208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_features,raw_labels=get_next_minibatch(minibatch_size)\n",
    "input=torch.from_numpy(raw_features)\n",
    "input=Variable(input)\n",
    "input=input.cuda()\n",
    "z_vae, mu, logvar = model2(input)\n",
    "results=z_vae.cpu().detach().numpy()\n",
    "#實際值\n",
    "actual=np.reshape(raw_features[0,:]*255,(28,28)).astype(np.uint8)\n",
    "pred=np.reshape(results[0,:]*255,(28,28)).astype(np.uint8)\n",
    "\n",
    "img=Image.fromarray(np.concatenate([actual,pred],axis=-1))\n",
    "plt.axis('off')\n",
    "plt.imshow(img, cmap='gray', interpolation='nearest')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
