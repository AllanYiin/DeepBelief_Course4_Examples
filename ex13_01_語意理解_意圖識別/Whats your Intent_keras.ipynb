{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 看穿你的意圖(keras版)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "意圖識別是機器與人透過語言交互的重要關鍵，因為發出命令者不一定會用固定的格式發言，因此機器必須要能夠根據句子內容來判斷發言者的實際意圖。本次數據集包含31種意圖(一個句子僅符合單一意圖)，接下來我們將介紹如何利用卷積神經網路進行自動意圖識別。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "首先我們讀取意圖列表，將他轉換為dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '打開app應用',\n",
       " 1: '詢問公車路線',\n",
       " 2: '數學計算',\n",
       " 3: '閒聊',\n",
       " 4: '詢問電影場次',\n",
       " 5: '查詢聯絡人',\n",
       " 6: '查詢食譜',\n",
       " 7: '詢問日期',\n",
       " 8: '電子郵件指令',\n",
       " 9: '詢問電視節目',\n",
       " 10: '詢問航班',\n",
       " 11: '詢問健康資訊',\n",
       " 12: '詢問樂透',\n",
       " 13: '詢問地圖',\n",
       " 14: '詢問足球賽事',\n",
       " 15: '簡訊指令',\n",
       " 16: '音樂指令',\n",
       " 17: '詢問新聞',\n",
       " 18: '詢問小說',\n",
       " 19: '詢問詩詞',\n",
       " 20: '詢問廣播節目',\n",
       " 21: '詢問謎語',\n",
       " 22: '鬧鐘時程設定',\n",
       " 23: '詢問股票',\n",
       " 24: '電話指令',\n",
       " 25: '詢問火車班次',\n",
       " 26: '詢問翻譯',\n",
       " 27: '切換電視頻道',\n",
       " 28: '影片播放指令',\n",
       " 29: '詢問天氣',\n",
       " 30: '開啟網站'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_data=codecs.open('intent_list.txt',mode='r',encoding='utf-8-sig').readlines()\n",
    "intent_dict={}\n",
    "for i in range(len(intent_data)):\n",
    "    intent_dict[i]=intent_data[i].strip() \n",
    "intent_dict"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "首先我們讀取一下訓練集數據，最長句子長度為52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大長度為:52\n",
      "2299\n"
     ]
    }
   ],
   "source": [
    "train_data=codecs.open('../Data/ex13_train/Intent_TrainData.txt',mode='r',encoding='utf-8-sig').readlines()\n",
    "maxlen=max([len(s) for s in train_data])\n",
    "print(\"最大長度為:{0}\".format(maxlen))\n",
    "print(len(train_data))\n",
    "print(train_data[:10])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "首先我們讀取一下訓練集數據，最長句子長度為69，為了避免發生句子過長無法全部納入的問題，因此我們將句子最大長度設定為128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最大長度為:69\n",
      "1437\n"
     ]
    }
   ],
   "source": [
    "test_data=codecs.open('../Data/ex13_train/Intent_TestData.txt',mode='r',encoding='utf-8-sig').readlines()\n",
    "maxlen=max([len(s) for s in test_data])\n",
    "print(\"最大長度為:{0}\".format(maxlen))\n",
    "print(len(test_data))\n",
    "print(test_data[:10])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "這次我們也還是一樣使用預訓練好的字向量，每個字轉換為對應長度為256的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars={}\n",
    "with open('hanzi2vec256.pkl','rb') as fp:\n",
    "    chars = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下來設計get_next_minibatch來讀取每個minibatch數據。每個句子長度128，不足部分以零填滿，若是出現未知字，則填入隨機亂數。為了提升模型的有效性，因此我們設計了文字的數據增強，包括隨機對調字的順序以及隨機插入贅字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.75009847  0.09500695  0.91376895 ...  1.0337592   1.3697404\n",
      "   -0.59126204]\n",
      "  [ 0.60782826 -1.3320998  -1.4303396  ... -0.7824813  -0.9995339\n",
      "   -0.7356023 ]\n",
      "  [ 0.60782826 -1.3320998  -1.4303396  ... -0.7824813  -0.9995339\n",
      "   -0.7356023 ]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[ 0.3429284   0.7419523   0.1245196  ... -0.07776023 -0.6644042\n",
      "   -0.09694016]\n",
      "  [-0.59841084  0.6645831   0.3415414  ...  1.1762546  -0.10037854\n",
      "    0.29701737]\n",
      "  [-1.3728026   0.94152653  0.47251025 ...  0.39836767  0.5001551\n",
      "    0.44415528]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]\n",
      "\n",
      " [[-0.51127464  0.45640758  0.56758267 ...  0.46686146  0.20309363\n",
      "   -0.48546994]\n",
      "  [-0.57380134 -0.41666427  0.06421938 ... -0.11115713 -0.9845447\n",
      "   -0.25247172]\n",
      "  [ 0.18636352  0.27117118 -0.7635313  ...  0.94250727  0.12556465\n",
      "    0.16363221]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0.]]\n",
      "[['美', '国', '最', '近', '有', '什', '么', '新', '闻'], ['我', '不', '吃', '英', '文', '怎', '么', '讲'], ['铁', '板', '烧', '怎', '么', '做', '？']]\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(train_data) #把訓練數據集順序打亂\n",
    "random.shuffle(test_data) #把訓練數據集順序打亂\n",
    "idx0=0\n",
    "idx1=0\n",
    "\n",
    "def data_augumentation(txt):\n",
    "    txt=list(txt)\n",
    "    if random.randint(0,10)<=3 and len(txt)>6:#隨機對調字的順序\n",
    "        pos= random.randint(1,len(txt)-2)\n",
    "        w1=txt[pos]\n",
    "        w2=txt[pos+1]\n",
    "        txt[pos]=w2\n",
    "        txt[pos+1]=w1\n",
    "    if random.randint(0,100)%7<2 and len(txt)>=6:\n",
    "        wordlist=['的','了','若','可','然','也','或','，','。',' ','  ']\n",
    "        w1=random.choice(wordlist)\n",
    "        txt.insert(random.randint(1,len(txt)-2), w1)\n",
    "    if random.randint(0,100)%5<2:\n",
    "        wordlist=['，','。','？','！',' ','  ']\n",
    "        w1=random.choice(wordlist)\n",
    "        txt.append(w1)\n",
    "    return ''.join(txt)\n",
    "\n",
    "def get_next_minibatch(minibatch_size=16,is_train=True):\n",
    "    global idx0,idx1\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "    groundtruths = []\n",
    "    while len(features) < minibatch_size:\n",
    "        try:\n",
    "            items=[]\n",
    "            if is_train:\n",
    "                items=train_data[idx0].strip().split('\\t')\n",
    "            else:\n",
    "                items=test_data[idx1].strip().split('\\t')\n",
    "            txt=items[0]\n",
    "            new_txt=items[0]\n",
    "            if is_train:\n",
    "                new_txt=data_augumentation(new_txt)\n",
    "            lab=int(items[1])\n",
    "            feature=np.zeros((256,128)) #預設都為零\n",
    "            label=np.zeros(31)\n",
    "            label[lab]=1\n",
    "            for i in range(128):\n",
    "                if i< len(new_txt):\n",
    "                    feature[:,i]=chars[new_txt[i].lower()] if new_txt[i].lower() in chars else np.random.uniform(-1,1,256)\n",
    "                    #替換為字向量，若是沒有這個字，填隨機亂數\n",
    "            features.append(feature.transpose())\n",
    "            labels.append(label)\n",
    "            groundtruths.append(list(txt))\n",
    "            if is_train:\n",
    "                idx0 += 1\n",
    "                if idx0 >= len(train_data):\n",
    "                    idx0 = 0\n",
    "                    random.shuffle(train_data)\n",
    "            else:\n",
    "                idx1 += 1\n",
    "                if idx1 >= len(test_data):\n",
    "                    idx1 = 0\n",
    "                    random.shuffle(test_data)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return np.asarray(features).astype(np.float32), np.asarray(labels).astype(np.float32), groundtruths\n",
    "\n",
    "\n",
    "features,labels,groundtruths=get_next_minibatch(minibatch_size=3)\n",
    "print(features)\n",
    "print(labels)\n",
    "print(groundtruths)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "引用keras所需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.losses import *\n",
    "from keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在這邊是使用標準的TextCNN，為了有效將序列特徵尺寸縮小，因此需要將strides設為2(比較不建議使用一維池化，容易造成信息缺失)。所以TextCNN將3,5,7找出來的特徵concate在一起後，先透過長度為1的一維向量降維，在來則是扁平化後連接全連階層。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![md_images](../Images/textcnn.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#為了解決類別間不均衡的焦距損失\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))+K.categorical_crossentropy(y_true, y_pred)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "\n",
    "#keras通道在後\n",
    "model_input = Input(shape=(128,256))\n",
    "z = model_input\n",
    "z = Dropout(0.2)(z)\n",
    "# Convolutional block\n",
    "conv_blocks = []\n",
    "filter_sizes=[3,5,7]\n",
    "for sz in filter_sizes:\n",
    "    conv = Convolution1D(filters=64,\n",
    "                         kernel_size=sz,\n",
    "                         padding=\"same\",\n",
    "                         activation='relu',\n",
    "                         strides=2)(z)\n",
    "    conv_blocks.append(conv)\n",
    "z = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]\n",
    "z = Dropout(0.5)(z)\n",
    "model_output = Convolution1D(filters=64,\n",
    "                         kernel_size=3,\n",
    "                         padding=\"same\",\n",
    "                         activation='relu',\n",
    "                         strides=1)(z)\n",
    "model_output = Convolution1D(filters=16,\n",
    "                         kernel_size=1,\n",
    "                         padding=\"same\",\n",
    "                         activation='relu',\n",
    "                         strides=1)(model_output)\n",
    "model_output=Flatten()(model_output)\n",
    "model_output=Dense(31, activation=\"relu\")(model_output)\n",
    "model = Model(model_input, model_output)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "定義每次執行的流程，每100 minibatch則列印一下測試數據集的實際與預測答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2299\n",
      "Epoch 1/300\n",
      "2299/2299 [==============================] - 11s 5ms/step - loss: 7.8503 - acc: 0.1701\n",
      "4的平方根的立方加9的2次方根的3次方  (數學計算)=>(打開app應用)\n",
      "中超赛事预告，你。  (詢問足球賽事)=>(打開app應用)\n",
      "武汉理工大学在哪  (詢問地圖)=>(打開app應用)\n",
      "CCTV4中文国际  (切換電視頻道)=>(打開app應用)\n",
      "搜索大乐透的号码资讯  (詢問樂透)=>(打開app應用)\n",
      "Epoch 2/300\n",
      "2299/2299 [==============================] - 1s 648us/step - loss: 6.5095 - acc: 0.2018\n",
      "查询上海到丽江飞机票的价格  (詢問航班)=>(打開app應用)\n",
      "你怎么就知道我不会呢？  (閒聊)=>(打開app應用)\n",
      "姜堰到南京的火车  (詢問火車班次)=>(打開app應用)\n",
      "前天中央一套的节目单  (詢問電視節目)=>(打開app應用)\n",
      "郑州的天气怎么样  (詢問天氣)=>(打開app應用)\n",
      "Epoch 3/300\n",
      "2299/2299 [==============================] - 2s 768us/step - loss: 6.4147 - acc: 0.1979\n",
      "糖醋排骨怎么做？好了额，你。  (查詢食譜)=>(打開app應用)\n",
      "从东莞到厦门的火车票  (詢問火車班次)=>(打開app應用)\n",
      "中国建设银行的行情  (詢問股票)=>(打開app應用)\n",
      "那你男神是谁  (閒聊)=>(打開app應用)\n",
      "你QQ号吗诗多少  (閒聊)=>(打開app應用)\n",
      "Epoch 4/300\n",
      "2299/2299 [==============================] - 2s 934us/step - loss: 6.3774 - acc: 0.2088\n",
      "搜索米聊  (打開app應用)=>(打開app應用)\n",
      "我要给陈永信息  (簡訊指令)=>(打開app應用)\n",
      "呼叫王希  (電話指令)=>(打開app應用)\n",
      "去桂林的航班怎样  (詢問航班)=>(打開app應用)\n",
      "Epoch 5/300\n",
      "2299/2299 [==============================] - 2s 840us/step - loss: 6.3118 - acc: 0.2218\n",
      "你如何做螃蟹？  (查詢食譜)=>(打開app應用)\n",
      "喂我想看电影喂  (影片播放指令)=>(打開app應用)\n",
      "我想跟今天的新闻。  (詢問新聞)=>(打開app應用)\n",
      "请拨幺幺零  (電話指令)=>(打開app應用)\n",
      "播放一首倒带来听一听  (音樂指令)=>(打開app應用)\n",
      "Epoch 6/300\n",
      "2299/2299 [==============================] - 2s 851us/step - loss: 6.3905 - acc: 0.2249\n",
      "搜索凤凰古城位置  (詢問地圖)=>(打開app應用)\n",
      "二十五日去深圳的航班  (詢問航班)=>(打開app應用)\n",
      "煲鸡汤。  (查詢食譜)=>(打開app應用)\n",
      "背一首李白的诗来听听。  (詢問詩詞)=>(打開app應用)\n",
      "Epoch 7/300\n",
      "2299/2299 [==============================] - 2s 683us/step - loss: 6.4097 - acc: 0.2227\n",
      "怎么我问你什么你都不知道  (閒聊)=>(打開app應用)\n",
      "羊肉怎么烧？  (查詢食譜)=>(打開app應用)\n",
      "你有多少最爱啊  (閒聊)=>(打開app應用)\n",
      "十五分钟之后叫我。  (鬧鐘時程設定)=>(打開app應用)\n",
      "扬州炒饭  (查詢食譜)=>(打開app應用)\n",
      "Epoch 8/300\n",
      "2299/2299 [==============================] - 1s 640us/step - loss: 6.3724 - acc: 0.2231\n",
      "中国霸王花  (影片播放指令)=>(打開app應用)\n",
      "进入当乐网  (開啟網站)=>(打開app應用)\n",
      "进入手机qq  (打開app應用)=>(打開app應用)\n",
      "打开九幺五八聊天  (開啟網站)=>(打開app應用)\n",
      "豆沙包。  (查詢食譜)=>(打開app應用)\n",
      "Epoch 9/300\n",
      "2299/2299 [==============================] - 1s 652us/step - loss: 6.2746 - acc: 0.2301\n",
      "拨打幺三九幺三八九九三九九  (電話指令)=>(打開app應用)\n",
      "可以教教吗?  (閒聊)=>(打開app應用)\n",
      "老马的电话是多少  (查詢聯絡人)=>(打開app應用)\n",
      "白萝卜汤怎么做？  (查詢食譜)=>(打開app應用)\n",
      "面条怎么样煮啊？  (查詢食譜)=>(打開app應用)\n",
      "Epoch 10/300\n",
      "2299/2299 [==============================] - 2s 678us/step - loss: 6.2196 - acc: 0.2505\n",
      "北京西站在哪  (詢問地圖)=>(打開app應用)\n",
      "炝拌土豆丝。  (查詢食譜)=>(打開app應用)\n",
      "陈周的电话号码是多少  (查詢聯絡人)=>(打開app應用)\n",
      "我想出去旅游英文怎么说  (詢問翻譯)=>(打開app應用)\n",
      "给我查一下糖尿病如何治疗？  (詢問健康資訊)=>(打開app應用)\n",
      "Epoch 11/300\n",
      "2299/2299 [==============================] - 2s 665us/step - loss: 6.2246 - acc: 0.2649\n",
      "怎么这么热受不了了  (閒聊)=>(打開app應用)\n",
      "最近新上映的电视剧。  (影片播放指令)=>(打開app應用)\n",
      "你们这么爽  (閒聊)=>(打開app應用)\n",
      "小白菜拌豆腐怎么做呀？  (查詢食譜)=>(打開app應用)\n",
      "CCTV第一剧场  (切換電視頻道)=>(打開app應用)\n",
      "Epoch 12/300\n",
      "2299/2299 [==============================] - 2s 878us/step - loss: 6.2152 - acc: 0.2784\n",
      "湖南卫视的快乐大本营什么时候播  (詢問電視節目)=>(打開app應用)\n",
      "预约还珠格格第八集  (影片播放指令)=>(打開app應用)\n",
      "现在的日期  (詢問日期)=>(打開app應用)\n",
      "麻婆豆腐怎么做  (查詢食譜)=>(打開app應用)\n",
      "蝎子王蝎子王  (影片播放指令)=>(打開app應用)\n",
      "Epoch 13/300\n",
      "2299/2299 [==============================] - 2s 952us/step - loss: 6.4150 - acc: 0.2279\n",
      "苏泊尔股价大跌  (詢問股票)=>(打開app應用)\n",
      "美人心计电视连续剧  (影片播放指令)=>(打開app應用)\n",
      "我要订一张到宁波的动车票  (詢問火車班次)=>(打開app應用)\n",
      "离我最近的电影院。  (詢問電影場次)=>(打開app應用)\n",
      "发信息给瀌瀌  (簡訊指令)=>(打開app應用)\n",
      "Epoch 14/300\n",
      "2299/2299 [==============================] - 2s 920us/step - loss: 6.3561 - acc: 0.2175\n",
      "调频fm九十七点七  (詢問廣播節目)=>(打開app應用)\n",
      "虎林市电影院正在上映的大片  (詢問電影場次)=>(打開app應用)\n",
      "k新闻想听新闻。  (詢問新聞)=>(打開app應用)\n",
      "读一首古诗给我听。  (詢問詩詞)=>(打開app應用)\n",
      "54乘上45  (數學計算)=>(打開app應用)\n",
      "Epoch 15/300\n",
      "2299/2299 [==============================] - 2s 1ms/step - loss: 6.3057 - acc: 0.2244\n",
      "我要看现代言情小说  (詢問小說)=>(打開app應用)\n",
      "哦来一首忘情水  (音樂指令)=>(打開app應用)\n",
      "哥哥是谁  (閒聊)=>(打開app應用)\n",
      "帮我打开人人  (打開app應用)=>(打開app應用)\n",
      "到安徽芜湖怎么走  (詢問地圖)=>(打開app應用)\n",
      "Epoch 16/300\n",
      "2299/2299 [==============================] - 2s 862us/step - loss: 6.2396 - acc: 0.2388\n",
      "看一下今天晚上广西台有没有警戒线？  (詢問電視節目)=>(打開app應用)\n",
      "打电话给阿华  (電話指令)=>(打開app應用)\n",
      "熊出没啊  (影片播放指令)=>(打開app應用)\n",
      "请打电话给沈晨浩  (電話指令)=>(打開app應用)\n",
      "查询后天广州到上海的航班  (詢問航班)=>(打開app應用)\n",
      "Epoch 17/300\n",
      "2299/2299 [==============================] - 2s 808us/step - loss: 6.1955 - acc: 0.2775\n",
      "清蒸鱼怎么做？吴？  (查詢食譜)=>(打開app應用)\n",
      "我要看图文小说  (詢問小說)=>(打開app應用)\n",
      "了，鸡蛋怎么做？  (查詢食譜)=>(打開app應用)\n",
      "北京二  (切換電視頻道)=>(打開app應用)\n",
      "那你告诉我最新的热门电影吧。  (詢問電影場次)=>(打開app應用)\n",
      "Epoch 18/300\n",
      "2299/2299 [==============================] - 2s 826us/step - loss: 6.2014 - acc: 0.3054\n",
      "是不是笨笨你觉得你笨吗  (閒聊)=>(打開app應用)\n",
      "就拉下的饺子怎么做？  (查詢食譜)=>(打開app應用)\n",
      "银耳莲子粥怎么做  (查詢食譜)=>(打開app應用)\n",
      "拔丝芋头怎么做  (查詢食譜)=>(打開app應用)\n",
      "唐诗哦。  (詢問詩詞)=>(打開app應用)\n",
      "Epoch 19/300\n",
      " 800/2299 [=========>....................] - ETA: 1s - loss: 6.5978 - acc: 0.2288"
     ]
    }
   ],
   "source": [
    "minibatch_size=32\n",
    "def on_epoch_end(epoch,logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    x_pred, x_label, truths = get_next_minibatch(minibatch_size,is_train=False)\n",
    "    pred=model.predict(x_pred, verbose=0)[0]\n",
    "    model.save_weights('Models/textcnn_keras.h5',True)\n",
    "    for i in range(5):\n",
    "        sentence=truths[i]\n",
    "        if len(sentence)>=3:\n",
    "            result=np.argmax(pred[i])\n",
    "            label=np.argmax(x_label[i])\n",
    "            print('{0}  ({1})=>({2})'.format(''.join(sentence),intent_dict[label],intent_dict[result]))\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "x,y,truth=get_next_minibatch(len(train_data))\n",
    "print(len(x))\n",
    "model.fit(x, y,batch_size=minibatch_size,epochs=300,callbacks=[print_callback])\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
